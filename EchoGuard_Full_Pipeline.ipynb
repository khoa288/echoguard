{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKZHbFch4lze",
        "outputId": "2219ca29-aa3b-4ad6-99f2-75d25ade5db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jan 14 12:29:36 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0             53W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip -q install soundfile librosa tqdm scipy thop fvcore torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TLj7lBF56ev"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "\n",
        "# EfficientAT (for MobileNetV3 + DyMN + AugmentMelSTFT)\n",
        "if not os.path.exists(\"EfficientAT\"):\n",
        "    !git clone --depth 1 https://github.com/fschmid56/EfficientAT.git\n",
        "\n",
        "# REQUIRED: remove the following code in EfficientAT/helpers/utils.py (line 35-50)\n",
        "# import csv\n",
        "\n",
        "# # Load label\n",
        "# with open('metadata/class_labels_indices.csv', 'r') as f:\n",
        "#     reader = csv.reader(f, delimiter=',')\n",
        "#     lines = list(reader)\n",
        "\n",
        "# labels = []\n",
        "# ids = []    # Each label has a unique id such as \"/m/068hy\"\n",
        "# for i1 in range(1, len(lines)):\n",
        "#     id = lines[i1][1]\n",
        "#     label = lines[i1][2]\n",
        "#     ids.append(id)\n",
        "#     labels.append(label)\n",
        "\n",
        "# classes_num = len(labels)\n",
        "\n",
        "sys.path.append(\"/content/EfficientAT\")\n",
        "\n",
        "# Optional: silence wandb if it tries to init anywhere\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK5-4oVs6DCr",
        "outputId": "c2b268b6-2b0d-48a1-e71c-75d6a2589e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE = cuda\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "import soundfile as sf\n",
        "from scipy import signal\n",
        "\n",
        "# EfficientAT imports\n",
        "from models.preprocess import AugmentMelSTFT\n",
        "from models.mn.model import get_model as get_mobilenet\n",
        "from models.dymn.model import get_model as get_dymn\n",
        "from helpers.utils import NAME_TO_WIDTH\n",
        "\n",
        "# FLOPs/MACs helpers\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "\n",
        "def set_seed(seed: int = 1337):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(1337)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE =\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGHCEL-Q6pyF",
        "outputId": "0c537b12-2daf-4bff-ab12-fe592c14ddce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbNlfmpz6WK3",
        "outputId": "a457e9b4-8187-4631-fe11-00553fbf0b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUT_DIR: /content/echo_guard_runs\n"
          ]
        }
      ],
      "source": [
        "# ESC-50 (preprocessed to 32k) root folder:\n",
        "#  <ESC50_32K_ROOT>/\n",
        "#     audio_32k/\n",
        "#     meta/esc50.csv\n",
        "ESC50_32K_ROOT = \"/content/drive/MyDrive/ESC-50/esc50-32k\"\n",
        "\n",
        "# If you prefer using the uploaded csv you attached (optional):\n",
        "ESC50_CSV_FALLBACK = \"/mnt/data/esc50.csv\"  # works only if present in your runtime\n",
        "\n",
        "# Stage 2: BC-ResNet binary danger/safe (tau=1,3,8)\n",
        "# train_esc50_binary.py must be in the same working dir (/content)\n",
        "BCRESNET_CKPTS = {\n",
        "    \"bcresnet_tau1\": \"/content/bcresnet1.pt\",\n",
        "    \"bcresnet_tau3\": \"/content/bcresnet3.pt\",\n",
        "    \"bcresnet_tau8\": \"/content/bcresnet8.pt\"\n",
        "}\n",
        "\n",
        "# Stage 2: MobileNetV3 (0.4) binary danger/safe (your fine-tuned checkpoint)\n",
        "STAGE2_MN_MODEL_NAME = \"mn04_as\"  # width=0.4 convention in EfficientAT\n",
        "STAGE2_MN_CKPT = \"/content/mn04_as.pt\"\n",
        "STAGE2_MN_NUM_CLASSES = 2\n",
        "\n",
        "# Stage 3: DyMN-M (your fine-tuned checkpoint, 50-way ESC-50)\n",
        "STAGE3_DYMN_MODEL_NAME = \"dymn10_as\"  # change if you trained a different name\n",
        "STAGE3_DYMN_CKPT = \"/content/dymn10_as.pt\"\n",
        "STAGE3_NUM_CLASSES = 50\n",
        "\n",
        "# Output directory\n",
        "OUT_DIR = \"/content/echo_guard_runs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_seirX7Gqw",
        "outputId": "a4c81999-2623-4b96-8274-33761f651afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ESC50 rows: 2000\n",
            "            filename  fold  target        category  esc10  src_file take\n",
            "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
            "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
            "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
            "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
            "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A\n",
            "Unique categories: 50\n"
          ]
        }
      ],
      "source": [
        "def resolve_esc50_csv(root: str) -> str:\n",
        "    p1 = os.path.join(root, \"meta\", \"esc50.csv\")\n",
        "    if os.path.exists(p1):\n",
        "        return p1\n",
        "    if os.path.exists(ESC50_CSV_FALLBACK):\n",
        "        return ESC50_CSV_FALLBACK\n",
        "    raise FileNotFoundError(\"Cannot find esc50.csv. Put it under <root>/meta/esc50.csv or set ESC50_CSV_FALLBACK.\")\n",
        "\n",
        "def resolve_audio_path(root: str, filename: str) -> str:\n",
        "    # your dataset uses audio_32k/\n",
        "    p = os.path.join(root, \"audio_32k\", filename)\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Missing audio file: {p}\")\n",
        "    return p\n",
        "\n",
        "esc_csv = resolve_esc50_csv(ESC50_32K_ROOT)\n",
        "df = pd.read_csv(esc_csv)\n",
        "\n",
        "required_cols = {\"filename\", \"fold\", \"target\", \"category\"}\n",
        "assert required_cols.issubset(df.columns), f\"esc50.csv missing cols: {required_cols - set(df.columns)}\"\n",
        "\n",
        "print(\"ESC50 rows:\", len(df))\n",
        "print(df.head())\n",
        "print(\"Unique categories:\", df[\"category\"].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49hDVpCu7MBN",
        "outputId": "ae85e457-2d1d-4caf-ace2-bef25f70a4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emergency clips: 320 / 2000\n",
            "Emergency targets: {'car_horn': 43, 'clock_alarm': 37, 'crying_baby': 20, 'dog': 0, 'door_wood_knock': 30, 'glass_breaking': 39, 'siren': 42, 'thunderstorm': 19}\n"
          ]
        }
      ],
      "source": [
        "# Your FIXED emergency/danger labels (ESC-50 categories)\n",
        "EMERGENCY_CATS = {\n",
        "    \"siren\",\n",
        "    \"car_horn\",\n",
        "    \"glass_breaking\",\n",
        "    \"thunderstorm\",\n",
        "    \"crying_baby\",\n",
        "    \"dog\",\n",
        "    \"door_wood_knock\",\n",
        "    \"clock_alarm\",\n",
        "}\n",
        "\n",
        "# Build target<->category mapping from esc50.csv\n",
        "target_to_cat = dict(df[[\"target\", \"category\"]].drop_duplicates().values.tolist())\n",
        "cat_to_target = {v: k for k, v in target_to_cat.items()}\n",
        "\n",
        "# sanity: ensure all emergency classes exist\n",
        "missing = sorted([c for c in EMERGENCY_CATS if c not in cat_to_target])\n",
        "assert len(missing) == 0, f\"These emergency categories not found in esc50.csv: {missing}\"\n",
        "\n",
        "df[\"is_emergency\"] = df[\"category\"].isin(EMERGENCY_CATS).astype(int)\n",
        "\n",
        "print(\"Emergency clips:\", int(df[\"is_emergency\"].sum()), \"/\", len(df))\n",
        "print(\"Emergency targets:\", {c: cat_to_target[c] for c in sorted(EMERGENCY_CATS)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yllEAsen7T3z"
      },
      "outputs": [],
      "source": [
        "SR = 32000\n",
        "CLIP_S = 5.0\n",
        "CLIP_T = int(SR * CLIP_S)\n",
        "\n",
        "def load_audio_32k_5s(path: str, sr: int = SR, T: int = CLIP_T) -> np.ndarray:\n",
        "    wav, file_sr = sf.read(path, dtype=\"float32\", always_2d=False)\n",
        "    if wav.ndim > 1:\n",
        "        wav = wav.mean(axis=-1)  # mono\n",
        "\n",
        "    if file_sr != sr:\n",
        "        wav_t = torch.from_numpy(wav)\n",
        "        wav = torchaudio.functional.resample(wav_t, file_sr, sr).numpy().astype(np.float32)\n",
        "\n",
        "    if len(wav) < T:\n",
        "        wav = np.pad(wav, (0, T - len(wav)))\n",
        "    elif len(wav) > T:\n",
        "        # center crop for determinism\n",
        "        start = (len(wav) - T) // 2\n",
        "        wav = wav[start:start+T]\n",
        "\n",
        "    wav = np.clip(wav, -1.0, 1.0).astype(np.float32)\n",
        "    return wav\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii9T4yZO7Vag"
      },
      "outputs": [],
      "source": [
        "def strip_module_prefix(state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "    return {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
        "\n",
        "def extract_state_dict(ckpt: Any) -> Dict[str, torch.Tensor]:\n",
        "    # Supports: raw state_dict, or dict containing common keys\n",
        "    if isinstance(ckpt, dict):\n",
        "        if all(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
        "            return strip_module_prefix(ckpt)\n",
        "        for key in [\"state_dict\", \"model\", \"model_state_dict\", \"net\", \"weights\"]:\n",
        "            if key in ckpt and isinstance(ckpt[key], dict):\n",
        "                return strip_module_prefix(ckpt[key])\n",
        "        # last resort: tensor-like entries\n",
        "        tensor_like = {k: v for k, v in ckpt.items() if isinstance(v, torch.Tensor)}\n",
        "        if len(tensor_like) > 0:\n",
        "            return strip_module_prefix(tensor_like)\n",
        "    raise ValueError(\"Unsupported checkpoint format (cannot extract state_dict).\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def logits_to_pdanger(logits: torch.Tensor) -> torch.Tensor:\n",
        "    # Supports: [B], [B,1] => sigmoid; [B,2] => softmax[:,1]\n",
        "    if isinstance(logits, (tuple, list)):\n",
        "        logits = logits[0]\n",
        "    if logits.ndim == 1:\n",
        "        return torch.sigmoid(logits)\n",
        "    if logits.ndim == 2 and logits.size(1) == 1:\n",
        "        return torch.sigmoid(logits[:, 0])\n",
        "    if logits.ndim == 2 and logits.size(1) == 2:\n",
        "        return F.softmax(logits, dim=-1)[:, 1]\n",
        "    raise ValueError(f\"Unexpected logits shape: {tuple(logits.shape)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Du5Ii57XUc"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT:\n",
        "# Put train_esc50_binary.py into /content (same dir as this notebook)\n",
        "# It must define: AudioFrontend, BCResNetBinary\n",
        "from train_esc50_binary import AudioFrontend, BCResNetBinary\n",
        "\n",
        "def infer_tau_from_filename(path: str) -> Optional[float]:\n",
        "    base = os.path.basename(path).lower()\n",
        "    m = re.search(r\"bcresnet([0-9]+(?:\\.[0-9]+)?)\", base)\n",
        "    return float(m.group(1)) if m else None\n",
        "\n",
        "def load_bcresnet_binary(ckpt_path: str, device: str = DEVICE):\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    state = extract_state_dict(ckpt)\n",
        "\n",
        "    # tau must be known by constructor\n",
        "    tau = infer_tau_from_filename(ckpt_path)\n",
        "    if tau is None:\n",
        "        raise ValueError(f\"Cannot infer tau from filename: {ckpt_path}. Rename like bcresnet8.pt or pass a tau in filename.\")\n",
        "\n",
        "    # frontend (match your training defaults unless your train script encodes cfg elsewhere)\n",
        "    frontend = AudioFrontend(\n",
        "        sample_rate=SR,\n",
        "        n_mels=40,\n",
        "        win_ms=30.0,\n",
        "        hop_ms=10.0,\n",
        "        n_fft=1024,\n",
        "        cmvn=True,\n",
        "        specaug=False,\n",
        "        freq_mask_param=10,\n",
        "        time_mask_param=80,\n",
        "        num_freq_masks=2,\n",
        "        num_time_masks=2,\n",
        "    ).to(device).eval()\n",
        "\n",
        "    model = BCResNetBinary(tau=float(tau)).to(device).eval()\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "    if len(unexpected) > 0:\n",
        "        print(\"[BCResNet] unexpected keys:\", unexpected[:5], \"...\")\n",
        "    if len(missing) > 0:\n",
        "        print(\"[BCResNet] missing keys:\", missing[:5], \"...\")\n",
        "\n",
        "    return tau, frontend, model\n",
        "\n",
        "@torch.no_grad()\n",
        "def bcresnet_predict_pdanger(frontend, model, wave_32k_5s: torch.Tensor) -> torch.Tensor:\n",
        "    # wave_32k_5s: (B, T) float\n",
        "    feats = frontend(wave_32k_5s, augment=False).float()\n",
        "    logits = model(feats)  # [B] logit\n",
        "    return torch.sigmoid(logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cHrQef17aN2",
        "outputId": "e92a04ce-b429-4b42-9167-ea8882247a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: FMAX is None setting to 15000 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:121: UserWarning: Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MN(\n",
            "  (features): Sequential(\n",
            "    (0): ConvNormActivation(\n",
            "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "          (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(8, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
            "              (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=48, out_features=16, bias=True)\n",
            "              (fc2): Linear(in_features=16, out_features=48, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=48, out_features=16, bias=True)\n",
            "              (fc2): Linear(in_features=16, out_features=48, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConvNormActivation(\n",
            "          (0): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=192, out_features=48, bias=True)\n",
            "              (fc2): Linear(in_features=48, out_features=192, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(48, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(272, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(272, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=272, bias=False)\n",
            "          (1): BatchNorm2d(272, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=272, out_features=72, bias=True)\n",
            "              (fc2): Linear(in_features=72, out_features=272, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(272, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(48, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(272, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(272, 272, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=272, bias=False)\n",
            "          (1): BatchNorm2d(272, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=272, out_features=72, bias=True)\n",
            "              (fc2): Linear(in_features=72, out_features=272, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(272, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "              (fc2): Linear(in_features=96, out_features=384, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): ConcurrentSEBlock(\n",
            "          (conc_se_layers): ModuleList(\n",
            "            (0): SqueezeExcitation(\n",
            "              (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "              (fc2): Linear(in_features=96, out_features=384, bias=True)\n",
            "              (activation): ReLU()\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ConvNormActivation(\n",
            "          (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): ConvNormActivation(\n",
            "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=384, out_features=512, bias=True)\n",
            "    (3): Hardswish()\n",
            "    (4): Dropout(p=0.2, inplace=True)\n",
            "    (5): Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "DyMN(\n",
            "  (layers): ModuleList(\n",
            "    (0): DY_Block(\n",
            "      (exp_conv): DynamicWrapper(\n",
            "        (module): Identity()\n",
            "      )\n",
            "      (exp_norm): Identity()\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Identity()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (1): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): ReLU(inplace=True)\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
            "      )\n",
            "    )\n",
            "    (2): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): ReLU(inplace=True)\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (3): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): ReLU(inplace=True)\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
            "      )\n",
            "    )\n",
            "    (4-5): 2 x DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): ReLU(inplace=True)\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (6): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
            "      )\n",
            "    )\n",
            "    (7): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (8-9): 2 x DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (10): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (11): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (12): DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
            "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
            "      )\n",
            "    )\n",
            "    (13-14): 2 x DY_Block(\n",
            "      (exp_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (exp_act): DynamicWrapper(\n",
            "        (module): Hardswish()\n",
            "      )\n",
            "      (depth_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (depth_act): DyReLUB(\n",
            "        (coef_net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
            "        )\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (ca): CoordAtt()\n",
            "      (proj_conv): DynamicConv(\n",
            "        (residuals): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (context_gen): ContextGen(\n",
            "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (joint_act): Hardswish()\n",
            "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (pool_f): Sequential()\n",
            "        (pool_t): Sequential()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (in_c): ConvNormActivation(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "    (2): Hardswish()\n",
            "  )\n",
            "  (out_c): ConvNormActivation(\n",
            "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "    (2): Hardswish()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=960, out_features=1280, bias=True)\n",
            "    (3): Hardswish()\n",
            "    (4): Dropout(p=0.2, inplace=True)\n",
            "    (5): Linear(in_features=1280, out_features=50, bias=True)\n",
            "  )\n",
            ")\n",
            "Loaded MN binary + DyMN 50-class.\n"
          ]
        }
      ],
      "source": [
        "def build_mel_extractor(device: str = DEVICE):\n",
        "    mel = AugmentMelSTFT(\n",
        "        n_mels=128, sr=SR, win_length=800, hopsize=320, n_fft=1024,\n",
        "        freqm=0, timem=0, fmin=0, fmax=None, fmin_aug_range=10, fmax_aug_range=2000\n",
        "    ).to(device)\n",
        "    mel.eval()\n",
        "    return mel\n",
        "\n",
        "@torch.no_grad()\n",
        "def wave_to_mel_128(mel: AugmentMelSTFT, wave_b1t: torch.Tensor) -> torch.Tensor:\n",
        "    # wave_b1t: (B,1,T)\n",
        "    B, C, T = wave_b1t.shape\n",
        "    x = wave_b1t.reshape(-1, T)      # (B, T)\n",
        "    xm = mel(x)                      # (B, 128, frames)\n",
        "    xm = xm.reshape(B, C, xm.shape[1], xm.shape[2])  # (B,1,128,frames)\n",
        "    return xm\n",
        "\n",
        "def load_efficientat_model(model_name: str, ckpt_path: str, num_classes: int, device: str = DEVICE):\n",
        "    width = NAME_TO_WIDTH(model_name)\n",
        "    if model_name.startswith(\"dymn\"):\n",
        "        model = get_dymn(width_mult=width, pretrained_name=None, pretrain_final_temp=1.0, num_classes=num_classes)\n",
        "    else:\n",
        "        model = get_mobilenet(width_mult=width, pretrained_name=None, head_type=\"mlp\", se_dims=\"c\", num_classes=num_classes)\n",
        "\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    state = extract_state_dict(ckpt)\n",
        "    model.load_state_dict(state, strict=True)\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "mel128 = build_mel_extractor()\n",
        "\n",
        "mn_bin = load_efficientat_model(STAGE2_MN_MODEL_NAME, STAGE2_MN_CKPT, STAGE2_MN_NUM_CLASSES)\n",
        "dymn_50 = load_efficientat_model(STAGE3_DYMN_MODEL_NAME, STAGE3_DYMN_CKPT, STAGE3_NUM_CLASSES)\n",
        "\n",
        "print(\"Loaded MN binary + DyMN 50-class.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MuztsP47fNT",
        "outputId": "bd7f9ce8-31e6-4a5b-fcfc-4d6f0606d5dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:681: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:875.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n",
            "/content/EfficientAT/models/preprocess.py:56: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dummy_mel shape: (1, 1, 128, 500)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::hardswish_ encountered 21 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 10 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::hardswish_ encountered 27 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 15 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 44 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 44 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 119 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 45 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 15 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 30 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::maximum encountered 15 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 10 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "m.layers.0.context_gen.pool_f, m.layers.0.context_gen.pool_t, m.layers.0.exp_act, m.layers.0.exp_conv, m.layers.10.context_gen.pool_f, m.layers.10.context_gen.pool_t, m.layers.11.context_gen.pool_f, m.layers.11.context_gen.pool_t, m.layers.13.context_gen.pool_f, m.layers.13.context_gen.pool_t, m.layers.14.context_gen.pool_f, m.layers.14.context_gen.pool_t, m.layers.2.context_gen.pool_f, m.layers.2.context_gen.pool_t, m.layers.4.context_gen.pool_f, m.layers.4.context_gen.pool_t, m.layers.5.context_gen.pool_f, m.layers.5.context_gen.pool_t, m.layers.7.context_gen.pool_f, m.layers.7.context_gen.pool_t, m.layers.8.context_gen.pool_f, m.layers.8.context_gen.pool_t, m.layers.9.context_gen.pool_f, m.layers.9.context_gen.pool_t\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MN ops: {'fvcore_ops': 60623616.0, 'thop_macs': 65430656.0}\n",
            "DyMN ops: {'fvcore_ops': 312468160.0, 'thop_macs': 58037024.0}\n",
            "dummy_feats shape (BCResNet input): (1, 1, 40, 501)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::silu_ encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::feature_dropout encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 20 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BCResNet ops: {'fvcore_ops': 15448868.0, 'thop_macs': 18022036.0}\n",
            "MACS proxies:\n",
            "  Stage2 MN: 65430656.0\n",
            "  Stage2 BC: 18022036.0\n",
            "  Stage3 DyMN: 58037024.0\n"
          ]
        }
      ],
      "source": [
        "def macs_from_fvcore(model: torch.nn.Module, inp: torch.Tensor) -> Optional[float]:\n",
        "    try:\n",
        "        flops = FlopCountAnalysis(model, inp).total()\n",
        "        # fvcore returns FLOPs; for convs, FLOPs ~ 2*MACs sometimes depending convention.\n",
        "        # We standardize by reporting \"Ops\" as returned, but also compute an approximate MAC count.\n",
        "        return float(flops)\n",
        "    except Exception as e:\n",
        "        print(\"[fvcore flopcount failed]:\", str(e)[:200])\n",
        "        return None\n",
        "\n",
        "def macs_from_thop(model: torch.nn.Module, inp: torch.Tensor) -> Optional[float]:\n",
        "    try:\n",
        "        from thop import profile\n",
        "        macs, params = profile(model, inputs=(inp,), verbose=False)\n",
        "        return float(macs)\n",
        "    except Exception as e:\n",
        "        print(\"[thop profile failed]:\", str(e)[:200])\n",
        "        return None\n",
        "\n",
        "def estimate_ops(model: torch.nn.Module, inp: torch.Tensor) -> Dict[str, Optional[float]]:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        fv = macs_from_fvcore(model, inp)\n",
        "        th = macs_from_thop(model, inp)\n",
        "    return {\"fvcore_ops\": fv, \"thop_macs\": th}\n",
        "\n",
        "# Dummy inputs (match your inference shapes)\n",
        "dummy_wave = torch.zeros(1, 1, CLIP_T, device=DEVICE)\n",
        "\n",
        "dummy_mel = wave_to_mel_128(mel128, dummy_wave)\n",
        "print(\"dummy_mel shape:\", tuple(dummy_mel.shape))\n",
        "\n",
        "# MN binary and DyMN 50 both take mel input and return (logits, _)\n",
        "class WrapEffAT(torch.nn.Module):\n",
        "    def __init__(self, m): super().__init__(); self.m=m\n",
        "    def forward(self, x):\n",
        "        out = self.m(x)\n",
        "        return out[0] if isinstance(out, (tuple,list)) else out\n",
        "\n",
        "mn_wrap = WrapEffAT(mn_bin).to(DEVICE)\n",
        "dymn_wrap = WrapEffAT(dymn_50).to(DEVICE)\n",
        "\n",
        "ops_mn = estimate_ops(mn_wrap, dummy_mel)\n",
        "ops_dymn = estimate_ops(dymn_wrap, dummy_mel)\n",
        "\n",
        "print(\"MN ops:\", ops_mn)\n",
        "print(\"DyMN ops:\", ops_dymn)\n",
        "\n",
        "# BC-ResNet: need its frontend output shape\n",
        "# (load tau=8 ckpt as representative to get shape; ops are usually similar across tau)\n",
        "_any_ckpt = list(BCRESNET_CKPTS.values())[0]\n",
        "tau_tmp, frontend_tmp, bc_tmp = load_bcresnet_binary(_any_ckpt, device=DEVICE)\n",
        "\n",
        "dummy_wave_bt = torch.zeros(1, CLIP_T, device=DEVICE)\n",
        "with torch.no_grad():\n",
        "    dummy_feats = frontend_tmp(dummy_wave_bt, augment=False).float()\n",
        "print(\"dummy_feats shape (BCResNet input):\", tuple(dummy_feats.shape))\n",
        "\n",
        "ops_bc = estimate_ops(bc_tmp, dummy_feats)\n",
        "print(\"BCResNet ops:\", ops_bc)\n",
        "\n",
        "# Pick one consistent MAC proxy:\n",
        "# Prefer thop_macs (more directly MAC-ish), fallback to fvcore_ops.\n",
        "def pick_macs(d: Dict[str, Optional[float]]) -> float:\n",
        "    if d[\"thop_macs\"] is not None:\n",
        "        return float(d[\"thop_macs\"])\n",
        "    if d[\"fvcore_ops\"] is not None:\n",
        "        return float(d[\"fvcore_ops\"])\n",
        "    return float(\"nan\")\n",
        "\n",
        "MACS_STAGE2_MN = pick_macs(ops_mn)\n",
        "MACS_STAGE3_DYMN = pick_macs(ops_dymn)\n",
        "MACS_STAGE2_BC   = pick_macs(ops_bc)\n",
        "\n",
        "print(\"MACS proxies:\")\n",
        "print(\"  Stage2 MN:\", MACS_STAGE2_MN)\n",
        "print(\"  Stage2 BC:\", MACS_STAGE2_BC)\n",
        "print(\"  Stage3 DyMN:\", MACS_STAGE3_DYMN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3w7Vx3v7p6j",
        "outputId": "91b014cd-6c03-4e46-c468-916b7b8e2d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage 1 DSP gates ready: ['S1_A_energy', 'S1_B_energy_flux', 'S1_C_sleep_aware']\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class DSPGateConfig:\n",
        "    sr: int = 16000\n",
        "    frame_s: float = 0.5\n",
        "    hop_s: float = 0.05\n",
        "    n_fft: int = 512\n",
        "\n",
        "    # noise tracking\n",
        "    ema_alpha: float = 0.02\n",
        "\n",
        "    # variant knobs\n",
        "    delta_db: float = 12.0         # energy over noise floor\n",
        "    flux_thr: float = 0.35         # normalized spectral flux\n",
        "    band_thr_db: float = 10.0      # band energy over noise floor\n",
        "    cooldown_s: float = 0.5        # avoid repeated triggers\n",
        "    hysteresis_frames: int = 2\n",
        "\n",
        "    # \"sleep mode\"\n",
        "    sleep_db: float = -45.0        # if long-term energy below this, relax thresholds\n",
        "    sleep_delta_db: float = 8.0\n",
        "    sleep_flux_thr: float = 0.25\n",
        "\n",
        "def downsample_to_16k(wave_32k: np.ndarray) -> np.ndarray:\n",
        "    w = torch.from_numpy(wave_32k)\n",
        "    w16 = torchaudio.functional.resample(w, SR, 16000).numpy().astype(np.float32)\n",
        "    return w16\n",
        "\n",
        "def frame_rms_db(x: np.ndarray, eps=1e-8) -> float:\n",
        "    rms = np.sqrt(np.mean(x*x) + eps)\n",
        "    return 20.0*np.log10(rms + eps)\n",
        "\n",
        "def spectral_flux(prev_mag: np.ndarray, mag: np.ndarray, eps=1e-8) -> float:\n",
        "    # normalized L1 positive changes\n",
        "    diff = np.maximum(mag - prev_mag, 0.0)\n",
        "    return float(np.sum(diff) / (np.sum(mag) + eps))\n",
        "\n",
        "def stft_mag(x: np.ndarray, n_fft: int) -> np.ndarray:\n",
        "    win = np.hanning(len(x)).astype(np.float32)\n",
        "    X = np.fft.rfft(x * win, n=n_fft)\n",
        "    return np.abs(X).astype(np.float32)\n",
        "\n",
        "def band_energies(mag: np.ndarray, sr: int, n_fft: int) -> np.ndarray:\n",
        "    # 4 broad bands: low/mid/high/very-high\n",
        "    freqs = np.fft.rfftfreq(n_fft, d=1/sr)\n",
        "    bands = [(0, 300), (300, 1200), (1200, 3000), (3000, sr/2)]\n",
        "    out = []\n",
        "    for lo, hi in bands:\n",
        "        idx = np.where((freqs >= lo) & (freqs < hi))[0]\n",
        "        out.append(float(np.mean(mag[idx] + 1e-8)))\n",
        "    return np.array(out, dtype=np.float32)\n",
        "\n",
        "class DSPGate:\n",
        "    \"\"\"\n",
        "    Returns triggers on hop grid. Designed to be cheap and high-recall.\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: DSPGateConfig, variant: str):\n",
        "        assert variant in [\"A_energy\", \"B_energy_flux\", \"C_sleep_aware\"]\n",
        "        self.cfg = cfg\n",
        "        self.variant = variant\n",
        "\n",
        "        self.noise_db = None\n",
        "        self.noise_band = None\n",
        "        self.prev_mag = None\n",
        "\n",
        "        self.cooldown_frames = int(round(cfg.cooldown_s / cfg.hop_s))\n",
        "        self.cooldown_left = 0\n",
        "        self.on_count = 0\n",
        "\n",
        "        # long-term for sleep mode\n",
        "        self.long_rms_ema = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.noise_db = None\n",
        "        self.noise_band = None\n",
        "        self.prev_mag = None\n",
        "        self.cooldown_left = 0\n",
        "        self.on_count = 0\n",
        "        self.long_rms_ema = None\n",
        "\n",
        "    def step(self, frame: np.ndarray) -> bool:\n",
        "        cfg = self.cfg\n",
        "\n",
        "        # update long RMS (for sleep mode)\n",
        "        rms_db = frame_rms_db(frame)\n",
        "        if self.long_rms_ema is None:\n",
        "            self.long_rms_ema = rms_db\n",
        "        else:\n",
        "            self.long_rms_ema = 0.995*self.long_rms_ema + 0.005*rms_db\n",
        "\n",
        "        # STFT magnitude + bands\n",
        "        mag = stft_mag(frame, cfg.n_fft)\n",
        "        bands = band_energies(mag, cfg.sr, cfg.n_fft)\n",
        "\n",
        "        # init noise trackers\n",
        "        if self.noise_db is None:\n",
        "            self.noise_db = rms_db\n",
        "            self.noise_band = bands.copy()\n",
        "            self.prev_mag = mag.copy()\n",
        "            return False\n",
        "\n",
        "        # EMA update (assume most frames are non-event)\n",
        "        self.noise_db = (1-cfg.ema_alpha)*self.noise_db + cfg.ema_alpha*rms_db\n",
        "        self.noise_band = (1-cfg.ema_alpha)*self.noise_band + cfg.ema_alpha*bands\n",
        "\n",
        "        # thresholds (sleep-aware)\n",
        "        delta_db = cfg.delta_db\n",
        "        flux_thr = cfg.flux_thr\n",
        "        if self.variant == \"C_sleep_aware\" and self.long_rms_ema < cfg.sleep_db:\n",
        "            delta_db = cfg.sleep_delta_db\n",
        "            flux_thr = cfg.sleep_flux_thr\n",
        "\n",
        "        # compute gates\n",
        "        energy_hit = (rms_db - self.noise_db) > delta_db\n",
        "\n",
        "        flux = spectral_flux(self.prev_mag, mag)\n",
        "        flux_hit = flux > flux_thr\n",
        "\n",
        "        # band hit: any band rises a lot over its noise estimate (in dB-ish)\n",
        "        band_ratio = (bands + 1e-6) / (self.noise_band + 1e-6)\n",
        "        band_hit = np.max(20*np.log10(band_ratio)) > cfg.band_thr_db\n",
        "\n",
        "        self.prev_mag = mag\n",
        "\n",
        "        if self.cooldown_left > 0:\n",
        "            self.cooldown_left -= 1\n",
        "            return False\n",
        "\n",
        "        if self.variant == \"A_energy\":\n",
        "            trig = energy_hit\n",
        "        elif self.variant == \"B_energy_flux\":\n",
        "            trig = energy_hit or (flux_hit and band_hit)\n",
        "        else:  # C_sleep_aware\n",
        "            # sleep-aware is more willing to trigger on flux/band even at low RMS\n",
        "            trig = energy_hit or flux_hit or band_hit\n",
        "\n",
        "        # hysteresis: require consecutive hits to declare event (reduces single-frame noise)\n",
        "        if trig:\n",
        "            self.on_count += 1\n",
        "        else:\n",
        "            self.on_count = max(0, self.on_count - 1)\n",
        "\n",
        "        if self.on_count >= cfg.hysteresis_frames:\n",
        "            self.on_count = 0\n",
        "            self.cooldown_left = self.cooldown_frames\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def run(self, wave_32k: np.ndarray) -> Tuple[np.ndarray, float]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          triggers: boolean array for each hop\n",
        "          sec_per_hop: hop duration seconds\n",
        "        \"\"\"\n",
        "        cfg = self.cfg\n",
        "        w16 = downsample_to_16k(wave_32k)\n",
        "\n",
        "        frame_len = int(cfg.frame_s * cfg.sr)\n",
        "        hop_len = int(cfg.hop_s * cfg.sr)\n",
        "\n",
        "        n_hops = 1 + max(0, (len(w16) - frame_len) // hop_len)\n",
        "        triggers = np.zeros(n_hops, dtype=np.bool_)\n",
        "\n",
        "        self.reset()\n",
        "        for i in range(n_hops):\n",
        "            s = i*hop_len\n",
        "            frame = w16[s:s+frame_len]\n",
        "            if len(frame) < frame_len:\n",
        "                frame = np.pad(frame, (0, frame_len - len(frame)))\n",
        "            triggers[i] = self.step(frame)\n",
        "\n",
        "        return triggers, cfg.hop_s\n",
        "\n",
        "# Create 3 gate variants\n",
        "gate_cfg = DSPGateConfig()\n",
        "DSP_GATES = {\n",
        "    \"S1_A_energy\": DSPGate(gate_cfg, \"A_energy\"),\n",
        "    \"S1_B_energy_flux\": DSPGate(gate_cfg, \"B_energy_flux\"),\n",
        "    \"S1_C_sleep_aware\": DSPGate(gate_cfg, \"C_sleep_aware\"),\n",
        "}\n",
        "\n",
        "print(\"Stage 1 DSP gates ready:\", list(DSP_GATES.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcqJgb0-7tPw",
        "outputId": "568e27b6-371c-40f0-f4f2-b21f5cb1e575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthetic soundscapes configured: ['quiet_home_day', 'sleep_night', 'busy_indoor', 'kitchen_like', 'outdoor_park', 'commute_like']\n"
          ]
        }
      ],
      "source": [
        "# --- Explicit categorization ---\n",
        "AMBIENT_CATS = {\n",
        "    \"rain\", \"sea_waves\", \"crickets\", \"chirping_birds\", \"wind\",\n",
        "    \"clock_tick\", \"washing_machine\", \"airplane\", \"helicopter\",\n",
        "    \"engine\", \"train\", \"church_bells\", \"water_drops\",\n",
        "}\n",
        "\n",
        "# Everything not emergency and not ambient becomes \"event-like safe\"\n",
        "ALL_CATS = set(df[\"category\"].unique())\n",
        "SAFE_EVENT_CATS = sorted(list(ALL_CATS - EMERGENCY_CATS - AMBIENT_CATS))\n",
        "\n",
        "def butter_lowpass(x: np.ndarray, sr: int, cutoff_hz: float) -> np.ndarray:\n",
        "    if cutoff_hz >= sr/2:\n",
        "        return x\n",
        "    b, a = signal.butter(2, cutoff_hz/(sr/2), btype=\"low\")\n",
        "    return signal.lfilter(b, a, x).astype(np.float32)\n",
        "\n",
        "def simple_reverb(x: np.ndarray, sr: int, rt60: float = 0.25) -> np.ndarray:\n",
        "    # lightweight synthetic RIR: exponential decay noise\n",
        "    rir_len = int(sr * min(0.5, max(0.05, rt60*1.2)))\n",
        "    t = np.arange(rir_len, dtype=np.float32) / sr\n",
        "    rir = (np.random.randn(rir_len).astype(np.float32) * np.exp(-t / max(1e-3, rt60))).astype(np.float32)\n",
        "    rir[0] += 1.0\n",
        "    y = signal.fftconvolve(x, rir, mode=\"full\")[:len(x)].astype(np.float32)\n",
        "    y = y / (np.max(np.abs(y)) + 1e-8) * (np.max(np.abs(x)) + 1e-8)\n",
        "    return y\n",
        "\n",
        "def apply_event_effects(x: np.ndarray, sr: int, kind: str, rng: np.random.RandomState) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    kind: \"bg\" | \"safe\" | \"emergency\"\n",
        "    \"\"\"\n",
        "    y = x.copy()\n",
        "\n",
        "    # mild reverb sometimes\n",
        "    if rng.rand() < (0.15 if kind != \"bg\" else 0.05):\n",
        "        rt60 = rng.uniform(0.12, 0.35)\n",
        "        y = simple_reverb(y, sr, rt60=rt60)\n",
        "\n",
        "    # occlusion / outside-room lowpass sometimes (important for \"quiet but real danger\")\n",
        "    if rng.rand() < (0.25 if kind == \"emergency\" else 0.12):\n",
        "        cutoff = rng.uniform(800, 3000)\n",
        "        y = butter_lowpass(y, sr, cutoff_hz=cutoff)\n",
        "\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "def set_snr(signal_x: np.ndarray, noise_x: np.ndarray, snr_db: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns scaled signal to achieve desired SNR wrt noise (both same length).\n",
        "    \"\"\"\n",
        "    eps = 1e-8\n",
        "    ps = np.mean(signal_x**2) + eps\n",
        "    pn = np.mean(noise_x**2) + eps\n",
        "    desired_ps = pn * (10**(snr_db/10))\n",
        "    scale = math.sqrt(desired_ps / ps)\n",
        "    return (signal_x * scale).astype(np.float32)\n",
        "\n",
        "@dataclass\n",
        "class ScenarioConfig:\n",
        "    name: str\n",
        "    duration_s: float\n",
        "    bg_level_db: Tuple[float, float]             # base loudness range\n",
        "    safe_events_per_min: Tuple[float, float]\n",
        "    emerg_events_per_min: Tuple[float, float]\n",
        "    emerg_snr_db: Tuple[float, float]            # relative to background\n",
        "    safe_snr_db: Tuple[float, float]\n",
        "    overlap_prob: float\n",
        "    night_mode: bool = False\n",
        "\n",
        "SCENARIOS = [\n",
        "    ScenarioConfig(\n",
        "        name=\"quiet_home_day\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-38, -30),\n",
        "        safe_events_per_min=(1.0, 2.5),\n",
        "        emerg_events_per_min=(0.15, 0.35),\n",
        "        emerg_snr_db=(-2, 14),\n",
        "        safe_snr_db=(0, 16),\n",
        "        overlap_prob=0.10,\n",
        "        night_mode=False,\n",
        "    ),\n",
        "    ScenarioConfig(\n",
        "        name=\"sleep_night\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-55, -45),\n",
        "        safe_events_per_min=(0.2, 0.8),\n",
        "        emerg_events_per_min=(0.08, 0.22),\n",
        "        emerg_snr_db=(-8, 10),   # more quiet/far emergencies\n",
        "        safe_snr_db=(-4, 10),\n",
        "        overlap_prob=0.05,\n",
        "        night_mode=True,\n",
        "    ),\n",
        "    ScenarioConfig(\n",
        "        name=\"busy_indoor\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-30, -22),\n",
        "        safe_events_per_min=(2.0, 4.0),\n",
        "        emerg_events_per_min=(0.12, 0.30),\n",
        "        emerg_snr_db=(-5, 12),\n",
        "        safe_snr_db=(0, 12),\n",
        "        overlap_prob=0.20,\n",
        "        night_mode=False,\n",
        "    ),\n",
        "    ScenarioConfig(\n",
        "        name=\"kitchen_like\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-33, -24),\n",
        "        safe_events_per_min=(1.5, 3.0),\n",
        "        emerg_events_per_min=(0.12, 0.28),\n",
        "        emerg_snr_db=(-4, 12),\n",
        "        safe_snr_db=(0, 14),\n",
        "        overlap_prob=0.18,\n",
        "        night_mode=False,\n",
        "    ),\n",
        "    ScenarioConfig(\n",
        "        name=\"outdoor_park\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-36, -28),\n",
        "        safe_events_per_min=(1.0, 2.5),\n",
        "        emerg_events_per_min=(0.10, 0.25),\n",
        "        emerg_snr_db=(-6, 12),\n",
        "        safe_snr_db=(-2, 14),\n",
        "        overlap_prob=0.12,\n",
        "        night_mode=False,\n",
        "    ),\n",
        "    ScenarioConfig(\n",
        "        name=\"commute_like\",\n",
        "        duration_s=10*60,\n",
        "        bg_level_db=(-28, -20),\n",
        "        safe_events_per_min=(2.0, 4.5),\n",
        "        emerg_events_per_min=(0.15, 0.35),\n",
        "        emerg_snr_db=(-5, 10),\n",
        "        safe_snr_db=(0, 10),\n",
        "        overlap_prob=0.25,\n",
        "        night_mode=False,\n",
        "    ),\n",
        "]\n",
        "\n",
        "def sample_clip_by_category(category: str, rng: np.random.RandomState) -> np.ndarray:\n",
        "    rows = df[df[\"category\"] == category]\n",
        "    idx = int(rng.choice(rows.index.values))\n",
        "    path = resolve_audio_path(ESC50_32K_ROOT, df.loc[idx, \"filename\"])\n",
        "    return load_audio_32k_5s(path)\n",
        "\n",
        "def build_background(duration_s: float, rng: np.random.RandomState, level_db: float) -> np.ndarray:\n",
        "    T = int(SR * duration_s)\n",
        "    y = np.zeros(T, dtype=np.float32)\n",
        "\n",
        "    # base: low gaussian noise\n",
        "    noise = rng.randn(T).astype(np.float32)\n",
        "    noise = noise / (np.std(noise) + 1e-8)\n",
        "    noise_gain = 10**(level_db/20)\n",
        "    y += noise * noise_gain * 0.2\n",
        "\n",
        "    # add tiled ambient clips\n",
        "    pos = 0\n",
        "    amb_list = list(AMBIENT_CATS & set(df[\"category\"].unique()))\n",
        "    if len(amb_list) == 0:\n",
        "        return np.clip(y, -1, 1)\n",
        "\n",
        "    while pos < T:\n",
        "        cat = rng.choice(amb_list)\n",
        "        clip = sample_clip_by_category(cat, rng)\n",
        "        clip = apply_event_effects(clip, SR, \"bg\", rng)\n",
        "\n",
        "        # random gain around background\n",
        "        g_db = rng.uniform(level_db - 6, level_db + 3)\n",
        "        g = 10**(g_db/20)\n",
        "        clip = clip * g\n",
        "\n",
        "        end = min(T, pos + len(clip))\n",
        "        y[pos:end] += clip[:end-pos]\n",
        "        pos = end\n",
        "\n",
        "    return np.clip(y, -1.0, 1.0)\n",
        "\n",
        "def poisson_event_times(rate_per_min: float, duration_s: float, rng: np.random.RandomState) -> List[float]:\n",
        "    rate_per_s = rate_per_min / 60.0\n",
        "    t = 0.0\n",
        "    out = []\n",
        "    while t < duration_s:\n",
        "        # exponential inter-arrival\n",
        "        dt = rng.exponential(1.0 / max(1e-6, rate_per_s))\n",
        "        t += dt\n",
        "        if t < duration_s:\n",
        "            out.append(float(t))\n",
        "    return out\n",
        "\n",
        "def overlay_events(base: np.ndarray, scen: ScenarioConfig, rng: np.random.RandomState) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
        "    duration_s = scen.duration_s\n",
        "    y = base.copy()\n",
        "    ann = []\n",
        "\n",
        "    # choose categories pool\n",
        "    emerg_pool = sorted(list(EMERGENCY_CATS))\n",
        "    safe_pool = SAFE_EVENT_CATS\n",
        "\n",
        "    safe_rate = rng.uniform(*scen.safe_events_per_min)\n",
        "    emerg_rate = rng.uniform(*scen.emerg_events_per_min)\n",
        "\n",
        "    safe_times = poisson_event_times(safe_rate, duration_s, rng)\n",
        "    emerg_times = poisson_event_times(emerg_rate, duration_s, rng)\n",
        "\n",
        "    def do_one_event(t_s: float, kind: str):\n",
        "        cat = rng.choice(emerg_pool) if kind == \"emergency\" else rng.choice(safe_pool)\n",
        "        clip = sample_clip_by_category(cat, rng)\n",
        "        clip = apply_event_effects(clip, SR, kind, rng)\n",
        "\n",
        "        # sometimes overlap by shifting start earlier (burstiness)\n",
        "        if rng.rand() < scen.overlap_prob:\n",
        "            t_s = max(0.0, t_s - rng.uniform(0.1, 1.5))\n",
        "\n",
        "        start = int(t_s * SR)\n",
        "        end = min(len(y), start + len(clip))\n",
        "        clip = clip[:end-start]\n",
        "\n",
        "        # set SNR relative to local background segment\n",
        "        bg_seg = y[start:end].copy()\n",
        "        if len(bg_seg) < 32:\n",
        "            return\n",
        "\n",
        "        snr_db = rng.uniform(*(scen.emerg_snr_db if kind==\"emergency\" else scen.safe_snr_db))\n",
        "        clip = set_snr(clip, bg_seg, snr_db)\n",
        "\n",
        "        y[start:end] = np.clip(y[start:end] + clip, -1.0, 1.0)\n",
        "\n",
        "        ann.append({\n",
        "            \"t_start\": start / SR,\n",
        "            \"t_end\": end / SR,\n",
        "            \"category\": str(cat),\n",
        "            \"kind\": kind,\n",
        "            \"snr_db\": float(snr_db),\n",
        "        })\n",
        "\n",
        "    for t_s in safe_times:\n",
        "        do_one_event(t_s, \"safe\")\n",
        "    for t_s in emerg_times:\n",
        "        do_one_event(t_s, \"emergency\")\n",
        "\n",
        "    ann = sorted(ann, key=lambda d: d[\"t_start\"])\n",
        "    return y, ann\n",
        "\n",
        "def build_soundscape(scen: ScenarioConfig, seed: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
        "    rng = np.random.RandomState(seed)\n",
        "    bg_level = rng.uniform(*scen.bg_level_db)\n",
        "    base = build_background(scen.duration_s, rng, level_db=bg_level)\n",
        "    y, ann = overlay_events(base, scen, rng)\n",
        "    return y, ann\n",
        "\n",
        "print(\"Synthetic soundscapes configured:\", [s.name for s in SCENARIOS])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VktQZjch7ziJ"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvalConfig:\n",
        "    decision_hop_s: float = 0.5     # how often we make a final decision (and compute EF1 windows)\n",
        "    label_win_s: float = 1.0        # ground-truth window length for EF1 labeling\n",
        "    stage2_gate: float = 0.5        # p(danger) threshold to invoke stage3\n",
        "    stage2_uncert_lo: Optional[float] = None  # e.g. 0.4\n",
        "    stage2_uncert_hi: Optional[float] = None  # e.g. 0.6\n",
        "\n",
        "EVAL_CFG = EvalConfig()\n",
        "\n",
        "def get_trailing_5s(wave: np.ndarray, t_end_s: float) -> np.ndarray:\n",
        "    end = int(t_end_s * SR)\n",
        "    start = end - CLIP_T\n",
        "    if start < 0:\n",
        "        seg = np.pad(wave[:end], (abs(start), 0))\n",
        "    else:\n",
        "        seg = wave[start:end]\n",
        "    if len(seg) < CLIP_T:\n",
        "        seg = np.pad(seg, (0, CLIP_T - len(seg)))\n",
        "    return seg.astype(np.float32)\n",
        "\n",
        "def build_gt_emergency_windows(ann: List[Dict[str, Any]], duration_s: float, hop_s: float, label_win_s: float) -> np.ndarray:\n",
        "    times = np.arange(hop_s, duration_s + 1e-6, hop_s)\n",
        "    y = np.zeros(len(times), dtype=np.int64)\n",
        "\n",
        "    # mark window positive if overlaps any emergency event within [t-label_win, t]\n",
        "    for i, t in enumerate(times):\n",
        "        w0, w1 = t - label_win_s, t\n",
        "        for a in ann:\n",
        "            if a[\"kind\"] == \"emergency\":\n",
        "                if not (a[\"t_end\"] <= w0 or a[\"t_start\"] >= w1):\n",
        "                    y[i] = 1\n",
        "                    break\n",
        "    return y\n",
        "\n",
        "@torch.no_grad()\n",
        "def stage3_predict_target(wave_5s: torch.Tensor) -> torch.Tensor:\n",
        "    # wave_5s: (B,1,T)\n",
        "    xm = wave_to_mel_128(mel128, wave_5s)\n",
        "    logits = dymn_50(xm)[0]  # (B,50)\n",
        "    return logits.argmax(dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def stage2_mn_pdanger(wave_5s: torch.Tensor) -> torch.Tensor:\n",
        "    xm = wave_to_mel_128(mel128, wave_5s)\n",
        "    logits = mn_bin(xm)[0]   # (B,2)\n",
        "    return logits_to_pdanger(logits)\n",
        "\n",
        "def stage2_policy(p: float, cfg: EvalConfig) -> bool:\n",
        "    if cfg.stage2_uncert_lo is not None and cfg.stage2_uncert_hi is not None:\n",
        "        # escalate if danger OR uncertain (recall-friendly)\n",
        "        return (p >= cfg.stage2_gate) or (cfg.stage2_uncert_lo <= p <= cfg.stage2_uncert_hi)\n",
        "    return (p >= cfg.stage2_gate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0adyKvF672RX",
        "outputId": "dddf4d30-4762-4e2b-8b93-75fc9b56f3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 proxy MAC/call: 36864.0\n"
          ]
        }
      ],
      "source": [
        "def f1_precision_recall(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, float, float]:\n",
        "    tp = int(((y_true==1) & (y_pred==1)).sum())\n",
        "    fp = int(((y_true==0) & (y_pred==1)).sum())\n",
        "    fn = int(((y_true==1) & (y_pred==0)).sum())\n",
        "    prec = tp / max(1, tp+fp)\n",
        "    rec  = tp / max(1, tp+fn)\n",
        "    f1 = 0.0 if (prec+rec)==0 else 2*prec*rec/(prec+rec)\n",
        "    return float(f1), float(prec), float(rec)\n",
        "\n",
        "def auroc_from_scores(y_true: np.ndarray, score: np.ndarray) -> float:\n",
        "    # simple AUROC without sklearn\n",
        "    # rank-based (MannWhitney U)\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    score = score.astype(np.float64)\n",
        "    pos = score[y_true==1]\n",
        "    neg = score[y_true==0]\n",
        "    if len(pos)==0 or len(neg)==0:\n",
        "        return float(\"nan\")\n",
        "    # compute probability pos>neg + 0.5 ties\n",
        "    count = 0.0\n",
        "    for p in pos:\n",
        "        count += np.sum(p > neg) + 0.5*np.sum(p == neg)\n",
        "    return float(count / (len(pos)*len(neg)))\n",
        "\n",
        "def event_ttd(ann: List[Dict[str, Any]], decision_times: np.ndarray, pred_emergency: np.ndarray, tol_s: float = 2.0) -> float:\n",
        "    \"\"\"\n",
        "    Time-to-detection: for each emergency event, find earliest predicted emergency in [start, end+tol],\n",
        "    return median delay (sec). If no detections, return NaN.\n",
        "    \"\"\"\n",
        "    delays = []\n",
        "    for a in ann:\n",
        "        if a[\"kind\"] != \"emergency\":\n",
        "            continue\n",
        "        start = a[\"t_start\"]\n",
        "        end = a[\"t_end\"] + tol_s\n",
        "        idx = np.where((decision_times >= start) & (decision_times <= end) & (pred_emergency==1))[0]\n",
        "        if len(idx) > 0:\n",
        "            delays.append(float(decision_times[idx[0]] - start))\n",
        "    if len(delays) == 0:\n",
        "        return float(\"nan\")\n",
        "    return float(np.median(delays))\n",
        "\n",
        "def compute_cavg_macs(duration_s: float,\n",
        "                      n_stage1_calls: int,\n",
        "                      n_stage2_calls: int,\n",
        "                      n_stage3_calls: int,\n",
        "                      mac_stage1_per_call: float,\n",
        "                      mac_stage2_per_call: float,\n",
        "                      mac_stage3_per_call: float) -> float:\n",
        "    total = (n_stage1_calls*mac_stage1_per_call +\n",
        "             n_stage2_calls*mac_stage2_per_call +\n",
        "             n_stage3_calls*mac_stage3_per_call)\n",
        "    return float(total / max(1e-6, duration_s))\n",
        "\n",
        "# Stage1 MAC proxy:\n",
        "# We'll treat Stage1 as FFT-ish work per hop (very small vs NN), but still nonzero.\n",
        "# Rough proxy: k * n_fft*log2(n_fft) per hop; use k=8 to be conservative.\n",
        "def stage1_mac_proxy(cfg: DSPGateConfig) -> float:\n",
        "    n_fft = cfg.n_fft\n",
        "    per = 8.0 * n_fft * math.log2(n_fft)\n",
        "    return float(per)\n",
        "\n",
        "MAC_STAGE1_PER_CALL = stage1_mac_proxy(gate_cfg)\n",
        "print(\"Stage1 proxy MAC/call:\", MAC_STAGE1_PER_CALL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWL6yOWM74ej"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_single_clip_stage3(df_eval: pd.DataFrame, batch_size: int = 64) -> Dict[str, float]:\n",
        "    # Stage3 always-on over individual ESC-50 clips (50-way)\n",
        "    y_true_em = df_eval[\"is_emergency\"].values.astype(np.int64)\n",
        "    probs_em = []\n",
        "    preds_em = []\n",
        "\n",
        "    # optional: top1 acc\n",
        "    y_true_t = df_eval[\"target\"].values.astype(np.int64)\n",
        "    y_pred_t = []\n",
        "\n",
        "    for i in tqdm(range(0, len(df_eval), batch_size), desc=\"Stage3 single-clip\"):\n",
        "        sub = df_eval.iloc[i:i+batch_size]\n",
        "        waves = []\n",
        "        for fn in sub[\"filename\"].values:\n",
        "            path = resolve_audio_path(ESC50_32K_ROOT, fn)\n",
        "            waves.append(load_audio_32k_5s(path))\n",
        "        wave = torch.from_numpy(np.stack(waves))[:, None, :].to(DEVICE)  # (B,1,T)\n",
        "\n",
        "        xm = wave_to_mel_128(mel128, wave)\n",
        "        logits = dymn_50(xm)[0]  # (B,50)\n",
        "        p = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "        pred_t = p.argmax(axis=-1)\n",
        "\n",
        "        # emergency score = sum probs over emergency targets\n",
        "        em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "        p_em = p[:, em_targets].sum(axis=-1)\n",
        "        pred_em = (p_em >= 0.5).astype(np.int64)\n",
        "\n",
        "        probs_em.append(p_em)\n",
        "        preds_em.append(pred_em)\n",
        "        y_pred_t.append(pred_t)\n",
        "\n",
        "    probs_em = np.concatenate(probs_em)\n",
        "    preds_em = np.concatenate(preds_em)\n",
        "    y_pred_t = np.concatenate(y_pred_t)\n",
        "\n",
        "    ef1, prec, rec = f1_precision_recall(y_true_em, preds_em)\n",
        "    auroc = auroc_from_scores(y_true_em, probs_em)\n",
        "    acc = float((y_pred_t == y_true_t).mean())\n",
        "\n",
        "    # compute (always-on): one stage3 call per clip\n",
        "    cavg = compute_cavg_macs(\n",
        "        duration_s=len(df_eval)*CLIP_S,\n",
        "        n_stage1_calls=0,\n",
        "        n_stage2_calls=0,\n",
        "        n_stage3_calls=len(df_eval),\n",
        "        mac_stage1_per_call=MAC_STAGE1_PER_CALL,\n",
        "        mac_stage2_per_call=0.0,\n",
        "        mac_stage3_per_call=MACS_STAGE3_DYMN,\n",
        "    )\n",
        "    eui = ef1 / max(1e-9, cavg)\n",
        "\n",
        "    return {\n",
        "        \"EF1\": ef1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"Top1_Acc\": acc,\n",
        "        \"Cavg_MACs_per_s\": cavg,\n",
        "        \"EUI\": eui,\n",
        "        \"Stage3_calls\": int(len(df_eval)),\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_single_clip_stage2_stage3(df_eval: pd.DataFrame,\n",
        "                                 stage2_name: str,\n",
        "                                 stage2_type: str,\n",
        "                                 bc_frontend=None,\n",
        "                                 bc_model=None,\n",
        "                                 batch_size: int = 64,\n",
        "                                 cfg: EvalConfig = EVAL_CFG) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    stage2_type: \"mn\" or \"bc\"\n",
        "    pipeline: Stage2 always, Stage3 only if Stage2 escalates\n",
        "    output emergency = (Stage3 in E) if invoked else 0\n",
        "    \"\"\"\n",
        "    y_true_em = df_eval[\"is_emergency\"].values.astype(np.int64)\n",
        "\n",
        "    preds_em = []\n",
        "    scores_em = []\n",
        "    n_stage3 = 0\n",
        "\n",
        "    for i in tqdm(range(0, len(df_eval), batch_size), desc=f\"S2+S3 single-clip ({stage2_name})\"):\n",
        "        sub = df_eval.iloc[i:i+batch_size]\n",
        "        waves = []\n",
        "        for fn in sub[\"filename\"].values:\n",
        "            path = resolve_audio_path(ESC50_32K_ROOT, fn)\n",
        "            waves.append(load_audio_32k_5s(path))\n",
        "        wave = torch.from_numpy(np.stack(waves))[:, None, :].to(DEVICE)  # (B,1,T)\n",
        "\n",
        "        # Stage2 p(danger)\n",
        "        if stage2_type == \"mn\":\n",
        "            p_d = stage2_mn_pdanger(wave).detach().cpu().numpy()\n",
        "        else:\n",
        "            p_d = bcresnet_predict_pdanger(bc_frontend, bc_model, wave[:,0,:]).detach().cpu().numpy()\n",
        "\n",
        "        # decide escalation per item\n",
        "        esc = np.array([stage2_policy(float(p), cfg) for p in p_d], dtype=np.bool_)\n",
        "\n",
        "        # Stage3 only for escalated\n",
        "        pred_em = np.zeros(len(sub), dtype=np.int64)\n",
        "        score_em = np.zeros(len(sub), dtype=np.float32)\n",
        "\n",
        "        if esc.any():\n",
        "            idx = np.where(esc)[0]\n",
        "            wave_esc = wave[idx]\n",
        "            pred_t = stage3_predict_target(wave_esc).detach().cpu().numpy().astype(np.int64)\n",
        "            pred_cat = np.array([target_to_cat[int(t)] for t in pred_t], dtype=object)\n",
        "            pred_em[idx] = np.array([1 if c in EMERGENCY_CATS else 0 for c in pred_cat], dtype=np.int64)\n",
        "            score_em[idx] = p_d[idx]  # use stage2 probability as \"emergency-likelihood\" score proxy\n",
        "            n_stage3 += int(len(idx))\n",
        "\n",
        "        preds_em.append(pred_em)\n",
        "        scores_em.append(score_em)\n",
        "\n",
        "    preds_em = np.concatenate(preds_em)\n",
        "    scores_em = np.concatenate(scores_em)\n",
        "\n",
        "    ef1, prec, rec = f1_precision_recall(y_true_em, preds_em)\n",
        "    auroc = auroc_from_scores(y_true_em, scores_em)\n",
        "\n",
        "    duration = len(df_eval)*CLIP_S\n",
        "    cavg = compute_cavg_macs(\n",
        "        duration_s=duration,\n",
        "        n_stage1_calls=0,\n",
        "        n_stage2_calls=len(df_eval),\n",
        "        n_stage3_calls=n_stage3,\n",
        "        mac_stage1_per_call=MAC_STAGE1_PER_CALL,\n",
        "        mac_stage2_per_call=(MACS_STAGE2_MN if stage2_type==\"mn\" else MACS_STAGE2_BC),\n",
        "        mac_stage3_per_call=MACS_STAGE3_DYMN,\n",
        "    )\n",
        "    eui = ef1 / max(1e-9, cavg)\n",
        "\n",
        "    return {\n",
        "        \"EF1\": ef1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"Cavg_MACs_per_s\": cavg,\n",
        "        \"EUI\": eui,\n",
        "        \"Stage2_calls\": int(len(df_eval)),\n",
        "        \"Stage3_calls\": int(n_stage3),\n",
        "        \"Stage2_name\": stage2_name,\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_soundscape_pipeline(wave: np.ndarray,\n",
        "                           ann: List[Dict[str, Any]],\n",
        "                           pipeline: str,\n",
        "                           stage1_gate: Optional[DSPGate],\n",
        "                           stage2_name: Optional[str],\n",
        "                           stage2_type: Optional[str],\n",
        "                           bc_frontend=None,\n",
        "                           bc_model=None,\n",
        "                           cfg: EvalConfig = EVAL_CFG) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    pipelines:\n",
        "      \"S3\"                    : Stage3 on every decision hop (always-on)\n",
        "      \"S1+S3\"                 : Stage1 decides whether to run Stage3\n",
        "      \"S2+S3\"                 : Stage2 always, Stage3 conditional\n",
        "      \"S1+S2+S3\"              : Stage1 gate -> Stage2 -> Stage3 conditional\n",
        "    \"\"\"\n",
        "    duration_s = len(wave)/SR\n",
        "    decision_times = np.arange(cfg.decision_hop_s, duration_s + 1e-6, cfg.decision_hop_s)\n",
        "    y_true = build_gt_emergency_windows(ann, duration_s, cfg.decision_hop_s, cfg.label_win_s)\n",
        "\n",
        "    pred = np.zeros(len(decision_times), dtype=np.int64)\n",
        "    score = np.zeros(len(decision_times), dtype=np.float32)\n",
        "\n",
        "    # Stage1 triggers on its own hop grid; map into decision grid if used\n",
        "    stage1_trig = None\n",
        "    if stage1_gate is not None:\n",
        "        trig_hops, s1_hop = stage1_gate.run(wave)\n",
        "        # convert stage1 trigger times into seconds\n",
        "        trig_times = (np.where(trig_hops)[0] * s1_hop).astype(np.float32)\n",
        "        stage1_trig = trig_times\n",
        "\n",
        "    n_s1 = len(decision_times) if stage1_gate is not None else 0\n",
        "    n_s2 = 0\n",
        "    n_s3 = 0\n",
        "\n",
        "    # quick helper: is there a stage1 trigger in last label window?\n",
        "    def s1_fired_recent(t: float) -> bool:\n",
        "        if stage1_trig is None or len(stage1_trig)==0:\n",
        "            return False\n",
        "        w0, w1 = t - cfg.label_win_s, t\n",
        "        # any trigger in [w0, w1]\n",
        "        i0 = np.searchsorted(stage1_trig, w0, side=\"left\")\n",
        "        i1 = np.searchsorted(stage1_trig, w1, side=\"right\")\n",
        "        return i1 > i0\n",
        "\n",
        "    for i, t in enumerate(decision_times):\n",
        "        # decide which stages to run\n",
        "        run_s3 = False\n",
        "        run_s2 = False\n",
        "\n",
        "        if pipeline == \"S3\":\n",
        "            run_s3 = True\n",
        "        elif pipeline == \"S1+S3\":\n",
        "            run_s3 = s1_fired_recent(float(t))\n",
        "        elif pipeline == \"S2+S3\":\n",
        "            run_s2 = True\n",
        "        elif pipeline == \"S1+S2+S3\":\n",
        "            run_s2 = s1_fired_recent(float(t))\n",
        "        else:\n",
        "            raise ValueError(\"Unknown pipeline\")\n",
        "\n",
        "        # extract trailing 5s\n",
        "        seg = get_trailing_5s(wave, float(t))\n",
        "        wave_t = torch.from_numpy(seg)[None, None, :].to(DEVICE)\n",
        "\n",
        "        # Stage2\n",
        "        if run_s2:\n",
        "            n_s2 += 1\n",
        "            if stage2_type == \"mn\":\n",
        "                p_d = float(stage2_mn_pdanger(wave_t).item())\n",
        "            else:\n",
        "                p_d = float(bcresnet_predict_pdanger(bc_frontend, bc_model, wave_t[:,0,:]).item())\n",
        "            score[i] = p_d\n",
        "            run_s3 = stage2_policy(p_d, cfg)\n",
        "        else:\n",
        "            score[i] = 0.0\n",
        "\n",
        "        # Stage3\n",
        "        if run_s3:\n",
        "            n_s3 += 1\n",
        "            pred_t = int(stage3_predict_target(wave_t).item())\n",
        "            pred_cat = target_to_cat[pred_t]\n",
        "            pred[i] = 1 if pred_cat in EMERGENCY_CATS else 0\n",
        "            if pipeline == \"S3\" or pipeline == \"S1+S3\":\n",
        "                # if no stage2, use emergency score from stage3 probs (more informative)\n",
        "                xm = wave_to_mel_128(mel128, wave_t)\n",
        "                logits = dymn_50(xm)[0]\n",
        "                p = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
        "                em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "                score[i] = float(p[em_targets].sum())\n",
        "\n",
        "    ef1, prec, rec = f1_precision_recall(y_true, pred)\n",
        "    auroc = auroc_from_scores(y_true, score)\n",
        "\n",
        "    # TR / DER\n",
        "    tr = float(np.mean([s1_fired_recent(float(t)) for t in decision_times])) if stage1_gate is not None else float(\"nan\")\n",
        "    der = float(n_s3 / max(1, n_s1)) if stage1_gate is not None else float(n_s3 / max(1, len(decision_times)))\n",
        "\n",
        "    # TTD (event-level)\n",
        "    ttd = event_ttd(ann, decision_times, pred, tol_s=2.0)\n",
        "\n",
        "    # Compute (MACs/s)\n",
        "    mac_s2 = MACS_STAGE2_MN if (stage2_type==\"mn\") else MACS_STAGE2_BC\n",
        "    cavg = compute_cavg_macs(\n",
        "        duration_s=duration_s,\n",
        "        n_stage1_calls=n_s1,\n",
        "        n_stage2_calls=n_s2,\n",
        "        n_stage3_calls=n_s3,\n",
        "        mac_stage1_per_call=MAC_STAGE1_PER_CALL,\n",
        "        mac_stage2_per_call=mac_s2 if stage2_type is not None else 0.0,\n",
        "        mac_stage3_per_call=MACS_STAGE3_DYMN,\n",
        "    )\n",
        "    eui = ef1 / max(1e-9, cavg)\n",
        "\n",
        "    return {\n",
        "        \"EF1\": ef1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"TR\": tr, \"DER\": der, \"TTD_sec\": ttd,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": int(n_s1), \"Stage2_calls\": int(n_s2), \"Stage3_calls\": int(n_s3),\n",
        "        \"pipeline\": pipeline,\n",
        "        \"stage2_name\": stage2_name if stage2_name else \"\",\n",
        "        \"stage1_name\": \"\" if stage1_gate is None else \"DSP\",\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "0hyLFBtkemne",
        "outputId": "416908b2-bfec-4684-9ea3-ca29e8966f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SMOKE] df_eval_smoke: 32 | emergency: 16 | non-em: 16\n",
            "[SMOKE] Scenario: quiet_home_day 60 seconds\n",
            "[SMOKE] Loaded bcresnet_tau8 tau = 8.0\n",
            "[SMOKE] MN p(danger): 0.8393261432647705\n",
            "[SMOKE] BC p(danger): 0.8105898499488831\n",
            "[SMOKE] DyMN pred target: 19 | cat: thunderstorm\n",
            "[SMOKE] OK Stage3 single clips | EF1: 0.9677419354833091 | Cavg: 11607404.8\n",
            "[SMOKE] OK MN S2+S3 clips | EF1: 0.9677419354833091 | S3 calls: 16.0 | Cavg: 18889833.6\n",
            "[SMOKE] OK BC S2+S3 clips | EF1: 0.9677419354833091 | S3 calls: 22.0 | Cavg: 11584498.0\n",
            "[SMOKE] Soundscape: quiet_home_day len(s)= 60.0 events= 3 emerg= 1\n",
            "[SMOKE] Emergency intervals: [(36.0, 41.0, 'dog', 12.0, True)]\n",
            "[SMOKE] OK S3       | EF1=0.690 AUROC=0.593 TR=nan DER=1.0000 Cavg=1.16e+08 | calls S1/S2/S3 = 0/0/120\n",
            "[SMOKE] OK S1+S3    | EF1=0.690 AUROC=0.763 TR=0.0008 DER=10.0000 Cavg=1.04e+07 | calls S1/S2/S3 = 1191/0/10\n",
            "[SMOKE] OK S2+S3    | EF1=0.593 AUROC=0.705 TR=nan DER=0.0667 Cavg=1.39e+08 | calls S1/S2/S3 = 0/120/8\n",
            "[SMOKE] OK S1+S2+S3 | EF1=0.593 AUROC=0.763 TR=0.0008 DER=8.0000 Cavg=1.94e+07 | calls S1/S2/S3 = 1191/10/8\n",
            "[SMOKE] Saved: /content/echo_guard_runs/smoke_results.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"smoke_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"SMOKE_Stage3_single_clips\",\n          \"SMOKE_Stage2+Stage3_single_clips\",\n          \"SMOKE_S1+S2+S3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scenario\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"quiet_home_day\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SMOKE_S1_B_energy_flux\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stage2_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\",\n          \"mn04_binary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pipeline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"S3_single_clip\",\n          \"S2+S3_single_clip\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EF1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17902515393924825,\n        \"min\": 0.5925925925921317,\n        \"max\": 0.9677419354833091,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9677419354833091,\n          0.6896551724132937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6519112617670862e-14,\n        \"min\": 0.999999999999875,\n        \"max\": 0.9999999999999333,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9999999999999333,\n          0.9999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25161683670909263,\n        \"min\": 0.42105263157892525,\n        \"max\": 0.9374999999999415,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9374999999999415,\n          0.5263157894736565\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUROC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1542294274124403,\n        \"min\": 0.5930171964564878,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          0.99609375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0008396305625524769,\n        \"max\": 0.0008396305625524769,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0008396305625524769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.97058011369565,\n        \"min\": 0.06666666666666667,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cavg_MACs_per_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55618150.855501235,\n        \"min\": 10404587.733333332,\n        \"max\": 138599581.86666667,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          11607404.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EUI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3730138790424e-08,\n        \"min\": 4.275572729809589e-09,\n        \"max\": 8.353766693069558e-08,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          8.33728083200225e-08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage1_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 581.1484934408516,\n        \"min\": 0.0,\n        \"max\": 1191.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1191.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage2_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.14979445958881,\n        \"min\": 0.0,\n        \"max\": 120.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage3_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.26341834895364,\n        \"min\": 8.0,\n        \"max\": 120.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Top1_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 8,\n        \"max\": 15,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "smoke_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3aa0aefa-f2af-41ca-8a05-e6d0e6841e9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Experiment</th>\n",
              "      <th>Scenario</th>\n",
              "      <th>Stage1</th>\n",
              "      <th>stage2_name</th>\n",
              "      <th>pipeline</th>\n",
              "      <th>EF1</th>\n",
              "      <th>Prec</th>\n",
              "      <th>Rec</th>\n",
              "      <th>AUROC</th>\n",
              "      <th>TR</th>\n",
              "      <th>DER</th>\n",
              "      <th>Cavg_MACs_per_s</th>\n",
              "      <th>EUI</th>\n",
              "      <th>Stage1_calls</th>\n",
              "      <th>Stage2_calls</th>\n",
              "      <th>Stage3_calls</th>\n",
              "      <th>Top1_Acc</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SMOKE_Stage3_single_clips</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>S3_single_clip</td>\n",
              "      <td>0.967742</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.160740e+07</td>\n",
              "      <td>8.337281e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SMOKE_Stage2+Stage3_single_clips</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S2+S3_single_clip</td>\n",
              "      <td>0.967742</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.996094</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.888983e+07</td>\n",
              "      <td>5.123083e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SMOKE_Stage2+Stage3_single_clips</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S2+S3_single_clip</td>\n",
              "      <td>0.967742</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.910156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.158450e+07</td>\n",
              "      <td>8.353767e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SMOKE_S3</td>\n",
              "      <td>quiet_home_day</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>S3</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.593017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.160740e+08</td>\n",
              "      <td>5.941510e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SMOKE_S1+S3</td>\n",
              "      <td>quiet_home_day</td>\n",
              "      <td>SMOKE_S1_B_energy_flux</td>\n",
              "      <td></td>\n",
              "      <td>S1+S3</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.00084</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.040459e+07</td>\n",
              "      <td>6.628376e-08</td>\n",
              "      <td>1191.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SMOKE_S2+S3</td>\n",
              "      <td>quiet_home_day</td>\n",
              "      <td></td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S2+S3</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.705055</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>1.385996e+08</td>\n",
              "      <td>4.275573e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SMOKE_S1+S2+S3</td>\n",
              "      <td>quiet_home_day</td>\n",
              "      <td>SMOKE_S1_B_energy_flux</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.00084</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.937513e+07</td>\n",
              "      <td>3.058522e-08</td>\n",
              "      <td>1191.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aa0aefa-f2af-41ca-8a05-e6d0e6841e9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3aa0aefa-f2af-41ca-8a05-e6d0e6841e9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3aa0aefa-f2af-41ca-8a05-e6d0e6841e9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_47a5a253-3fbd-495b-82ea-9e58bacf6ede\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('smoke_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47a5a253-3fbd-495b-82ea-9e58bacf6ede button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('smoke_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         Experiment        Scenario                  Stage1  \\\n",
              "0         SMOKE_Stage3_single_clips                                     NaN   \n",
              "1  SMOKE_Stage2+Stage3_single_clips                                     NaN   \n",
              "2  SMOKE_Stage2+Stage3_single_clips                                     NaN   \n",
              "3                          SMOKE_S3  quiet_home_day                           \n",
              "4                       SMOKE_S1+S3  quiet_home_day  SMOKE_S1_B_energy_flux   \n",
              "5                       SMOKE_S2+S3  quiet_home_day                           \n",
              "6                    SMOKE_S1+S2+S3  quiet_home_day  SMOKE_S1_B_energy_flux   \n",
              "\n",
              "     stage2_name           pipeline       EF1  Prec       Rec     AUROC  \\\n",
              "0                    S3_single_clip  0.967742   1.0  0.937500  1.000000   \n",
              "1    mn04_binary  S2+S3_single_clip  0.967742   1.0  0.937500  0.996094   \n",
              "2  bcresnet_tau8  S2+S3_single_clip  0.967742   1.0  0.937500  0.910156   \n",
              "3                                S3  0.689655   1.0  0.526316  0.593017   \n",
              "4                             S1+S3  0.689655   1.0  0.526316  0.763158   \n",
              "5    mn04_binary              S2+S3  0.592593   1.0  0.421053  0.705055   \n",
              "6    mn04_binary           S1+S2+S3  0.592593   1.0  0.421053  0.763158   \n",
              "\n",
              "        TR        DER  Cavg_MACs_per_s           EUI  Stage1_calls  \\\n",
              "0      NaN        NaN     1.160740e+07  8.337281e-08           0.0   \n",
              "1      NaN        NaN     1.888983e+07  5.123083e-08           0.0   \n",
              "2      NaN        NaN     1.158450e+07  8.353767e-08           0.0   \n",
              "3      NaN   1.000000     1.160740e+08  5.941510e-09           0.0   \n",
              "4  0.00084  10.000000     1.040459e+07  6.628376e-08        1191.0   \n",
              "5      NaN   0.066667     1.385996e+08  4.275573e-09           0.0   \n",
              "6  0.00084   8.000000     1.937513e+07  3.058522e-08        1191.0   \n",
              "\n",
              "   Stage2_calls  Stage3_calls  Top1_Acc  TP  FP  FN  \n",
              "0           0.0          32.0       1.0  15   0   1  \n",
              "1          32.0          16.0       NaN  15   0   1  \n",
              "2          32.0          22.0       NaN  15   0   1  \n",
              "3           0.0         120.0       NaN  10   0   9  \n",
              "4           0.0          10.0       NaN  10   0   9  \n",
              "5         120.0           8.0       NaN   8   0  11  \n",
              "6          10.0           8.0       NaN   8   0  11  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SMOKE RUN\n",
        "# - Runs end-to-end assuming your main notebook cells already defined:\n",
        "#   df, ESC50_32K_ROOT, resolve_audio_path, load_audio_32k_5s, SR, CLIP_T, CLIP_S\n",
        "#   EMERGENCY_CATS, target_to_cat, cat_to_target\n",
        "#   build_soundscape, SCENARIOS, ScenarioConfig\n",
        "#   stage2_mn_pdanger, stage3_predict_target\n",
        "#   BCRESNET_CKPTS, load_bcresnet_binary, bcresnet_predict_pdanger\n",
        "#   DSPGateConfig, DSPGate\n",
        "#   MAC_STAGE1_PER_CALL, MACS_STAGE2_MN, MACS_STAGE2_BC, MACS_STAGE3_DYMN, compute_cavg_macs\n",
        "#   mel128, wave_to_mel_128, dymn_50 (for S3 score)\n",
        "# - Smoke:\n",
        "#   (1) Stage3 on 32 clips\n",
        "#   (2) Stage2+Stage3 on 32 clips (MN + BC tau8)\n",
        "#   (3) 1x 60s soundscape (forced >=1 emergency @ high SNR) with 4 pipelines:\n",
        "#       S3, S1+S3, S2+S3(MN), S1+S2+S3(MN)\n",
        "# - Saves: OUT_DIR/smoke_results.csv\n",
        "# ============================================================\n",
        "\n",
        "import os, math, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -----------------------------\n",
        "# Silence EfficientAT warning (optional)\n",
        "# -----------------------------\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*autocast.*deprecated.*\")\n",
        "\n",
        "# -----------------------------\n",
        "# Safety checks (must exist)\n",
        "# -----------------------------\n",
        "needed = [\n",
        "    \"df\", \"ESC50_32K_ROOT\", \"resolve_audio_path\", \"load_audio_32k_5s\", \"SR\", \"CLIP_T\", \"CLIP_S\",\n",
        "    \"EMERGENCY_CATS\", \"target_to_cat\", \"cat_to_target\",\n",
        "    \"SCENARIOS\", \"ScenarioConfig\", \"build_soundscape\",\n",
        "    \"BCRESNET_CKPTS\", \"load_bcresnet_binary\", \"bcresnet_predict_pdanger\",\n",
        "    \"stage2_mn_pdanger\", \"stage3_predict_target\",\n",
        "    \"DSPGateConfig\", \"DSPGate\",\n",
        "    \"OUT_DIR\", \"DEVICE\",\n",
        "    \"MAC_STAGE1_PER_CALL\", \"MACS_STAGE2_MN\", \"MACS_STAGE2_BC\", \"MACS_STAGE3_DYMN\", \"compute_cavg_macs\",\n",
        "    \"mel128\", \"wave_to_mel_128\", \"dymn_50\"\n",
        "]\n",
        "missing = [x for x in needed if x not in globals()]\n",
        "assert not missing, f\"Missing definitions: {missing}\"\n",
        "\n",
        "# -----------------------------\n",
        "# Smoke config\n",
        "# -----------------------------\n",
        "SMOKE_N_CLIPS     = 32\n",
        "SMOKE_DURATION_S  = 60\n",
        "SMOKE_SEED        = 0\n",
        "SMOKE_SCENARIOS   = 1\n",
        "\n",
        "# IMPORTANT: align soundscape labeling window with model input window\n",
        "LABEL_WIN_S = float(CLIP_S)  # 5.0\n",
        "\n",
        "class EvalConfig:\n",
        "    def __init__(self, decision_hop_s=0.5, label_win_s=5.0, stage2_gate=0.30, stage2_uncert_lo=0.25, stage2_uncert_hi=0.65):\n",
        "        self.decision_hop_s = decision_hop_s\n",
        "        self.label_win_s = label_win_s\n",
        "        self.stage2_gate = stage2_gate\n",
        "        self.stage2_uncert_lo = stage2_uncert_lo\n",
        "        self.stage2_uncert_hi = stage2_uncert_hi\n",
        "\n",
        "EVAL_CFG_SMOKE = EvalConfig(\n",
        "    decision_hop_s=0.5,\n",
        "    label_win_s=LABEL_WIN_S,\n",
        "    stage2_gate=0.30,\n",
        "    stage2_uncert_lo=0.25,\n",
        "    stage2_uncert_hi=0.65\n",
        ")\n",
        "\n",
        "# Stage1 gate: tight-ish but not too tight\n",
        "gate_cfg_smoke = DSPGateConfig(\n",
        "    sr=16000, frame_s=0.5, hop_s=0.05, n_fft=512,\n",
        "    ema_alpha=0.02,\n",
        "    delta_db=15.0,          # was 18 (too strict in 60s)\n",
        "    flux_thr=0.40,          # was 0.45\n",
        "    band_thr_db=14.0,\n",
        "    cooldown_s=0.8,\n",
        "    hysteresis_frames=3,\n",
        "    sleep_db=-48.0,\n",
        "    sleep_delta_db=12.0,\n",
        "    sleep_flux_thr=0.35,\n",
        ")\n",
        "S1_SMOKE_GATE = DSPGate(gate_cfg_smoke, \"B_energy_flux\")\n",
        "S1_SMOKE_NAME = \"SMOKE_S1_B_energy_flux\"\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers: metrics (no sklearn)\n",
        "# -----------------------------\n",
        "def _prec_rec_f1(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = np.asarray(y_pred).astype(int)\n",
        "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
        "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
        "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec  = tp / (tp + fn + 1e-12)\n",
        "    f1   = 2 * prec * rec / (prec + rec + 1e-12)\n",
        "    return float(prec), float(rec), float(f1), tp, fp, fn\n",
        "\n",
        "def _auroc_rank(y_true, y_score):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_score = np.asarray(y_score).astype(float)\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return float(\"nan\")\n",
        "    pos = y_score[y_true==1]\n",
        "    neg = y_score[y_true==0]\n",
        "    if len(pos)==0 or len(neg)==0:\n",
        "        return float(\"nan\")\n",
        "    cnt = 0.0\n",
        "    for p in pos:\n",
        "        cnt += np.sum(p > neg) + 0.5*np.sum(p == neg)\n",
        "    return float(cnt / (len(pos)*len(neg)))\n",
        "\n",
        "def _to_wave_tensor_from_filename(fn: str) -> torch.Tensor:\n",
        "    p = resolve_audio_path(ESC50_32K_ROOT, fn)\n",
        "    w = load_audio_32k_5s(p)  # (T,)\n",
        "    assert w.shape == (CLIP_T,), f\"bad wave shape: {w.shape}\"\n",
        "    return torch.from_numpy(w)[None, None, :].to(DEVICE)  # (1,1,T)\n",
        "\n",
        "# -----------------------------\n",
        "# Stage3 (single clips) smoke (no dependency on your earlier helper)\n",
        "# -----------------------------\n",
        "@torch.no_grad()\n",
        "def stage3_single_clips_smoke(df_eval: pd.DataFrame, batch_size: int = 16):\n",
        "    y_true = df_eval[\"is_emergency\"].astype(int).values\n",
        "    y_pred = []\n",
        "    y_score = []\n",
        "    y_t_true = df_eval[\"target\"].astype(int).values\n",
        "    y_t_pred = []\n",
        "\n",
        "    em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "\n",
        "    for i in range(0, len(df_eval), batch_size):\n",
        "        sub = df_eval.iloc[i:i+batch_size]\n",
        "        waves = []\n",
        "        for fn in sub[\"filename\"].values:\n",
        "            waves.append(load_audio_32k_5s(resolve_audio_path(ESC50_32K_ROOT, fn)))\n",
        "        x = torch.from_numpy(np.stack(waves))[:, None, :].to(DEVICE)  # (B,1,T)\n",
        "\n",
        "        xm = wave_to_mel_128(mel128, x)\n",
        "        logits = dymn_50(xm)[0]               # (B,50)\n",
        "        p = F.softmax(logits, dim=-1)         # (B,50)\n",
        "        p_np = p.detach().cpu().numpy()\n",
        "\n",
        "        pred_t = p_np.argmax(axis=-1)\n",
        "        y_t_pred.append(pred_t)\n",
        "\n",
        "        p_em = p_np[:, em_targets].sum(axis=-1)           # emergency probability mass\n",
        "        y_score.append(p_em)\n",
        "        y_pred.append((p_em >= 0.5).astype(int))\n",
        "\n",
        "    y_pred = np.concatenate(y_pred)\n",
        "    y_score = np.concatenate(y_score)\n",
        "    y_t_pred = np.concatenate(y_t_pred)\n",
        "\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "    top1 = float((y_t_pred == y_t_true).mean())\n",
        "\n",
        "    duration_s = len(df_eval) * float(CLIP_S)\n",
        "    cavg = compute_cavg_macs(duration_s, 0, 0, len(df_eval), MAC_STAGE1_PER_CALL, 0.0, MACS_STAGE3_DYMN)\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": \"S3_single_clip\",\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc, \"Top1_Acc\": top1,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": 0.0, \"Stage2_calls\": 0.0, \"Stage3_calls\": float(len(df_eval)),\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Stage2+Stage3 (single clips) smoke\n",
        "# -----------------------------\n",
        "@torch.no_grad()\n",
        "def stage2_stage3_single_clips_smoke(df_eval: pd.DataFrame, stage2_name: str, stage2_type: str, cfg: EvalConfig,\n",
        "                                     bc_frontend=None, bc_model=None):\n",
        "    y_true, y_pred, y_score = [], [], []\n",
        "    s2_calls, s3_calls = 0, 0\n",
        "\n",
        "    for i in range(len(df_eval)):\n",
        "        fn = df_eval.loc[i, \"filename\"]\n",
        "        yt = int(df_eval.loc[i, \"is_emergency\"])\n",
        "        x = _to_wave_tensor_from_filename(fn)\n",
        "\n",
        "        if stage2_type == \"mn\":\n",
        "            pdanger = float(stage2_mn_pdanger(x).item())\n",
        "            mac_s2 = MACS_STAGE2_MN\n",
        "        else:\n",
        "            pdanger = float(bcresnet_predict_pdanger(bc_frontend, bc_model, x[:, 0, :]).item())\n",
        "            mac_s2 = MACS_STAGE2_BC\n",
        "        s2_calls += 1\n",
        "\n",
        "        escalate = (pdanger >= cfg.stage2_gate)\n",
        "        if cfg.stage2_uncert_lo is not None and cfg.stage2_uncert_hi is not None:\n",
        "            escalate = escalate or (cfg.stage2_uncert_lo <= pdanger <= cfg.stage2_uncert_hi)\n",
        "\n",
        "        if not escalate:\n",
        "            yp = 0\n",
        "        else:\n",
        "            t = int(stage3_predict_target(x).item())\n",
        "            cat = target_to_cat[t]\n",
        "            yp = 1 if cat in EMERGENCY_CATS else 0\n",
        "            s3_calls += 1\n",
        "\n",
        "        y_true.append(yt); y_pred.append(yp); y_score.append(pdanger)\n",
        "\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "\n",
        "    duration_s = len(df_eval) * float(CLIP_S)\n",
        "    cavg = compute_cavg_macs(duration_s, 0, s2_calls, s3_calls, MAC_STAGE1_PER_CALL, mac_s2, MACS_STAGE3_DYMN)\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": \"S2+S3_single_clip\",\n",
        "        \"stage2_name\": stage2_name,\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": 0.0, \"Stage2_calls\": float(s2_calls), \"Stage3_calls\": float(s3_calls),\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Soundscape helpers: force >=1 emergency @ high SNR + align gating\n",
        "# -----------------------------\n",
        "def _rms(x: np.ndarray) -> float:\n",
        "    return float(np.sqrt(np.mean(x.astype(np.float32)**2) + 1e-12))\n",
        "\n",
        "def _mix_at_snr(bg: np.ndarray, sig: np.ndarray, snr_db: float) -> np.ndarray:\n",
        "    r_bg = _rms(bg)\n",
        "    r_sig = _rms(sig)\n",
        "    target_r_sig = r_bg * (10.0 ** (snr_db / 20.0))\n",
        "    scale = target_r_sig / (r_sig + 1e-12)\n",
        "    return (sig * scale).astype(np.float32)\n",
        "\n",
        "def ensure_min_emergencies_soundscape(wave: np.ndarray, ann: list, duration_s: float,\n",
        "                                      min_emerg: int = 1, seed: int = 0, inject_snr_db: float = 12.0):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n_em = sum(1 for a in ann if a.get(\"kind\") == \"emergency\")\n",
        "    if n_em >= min_emerg:\n",
        "        return wave, ann\n",
        "\n",
        "    df_em = df[df[\"category\"].isin(list(EMERGENCY_CATS))]\n",
        "    assert len(df_em) > 0, \"No emergency clips found in df; check EMERGENCY_CATS vs esc50.csv categories.\"\n",
        "    row = df_em.sample(n=1, random_state=seed).iloc[0]\n",
        "    clip = load_audio_32k_5s(resolve_audio_path(ESC50_32K_ROOT, row[\"filename\"]))  # 5s\n",
        "\n",
        "    # inject in middle\n",
        "    t_s = max(CLIP_S, min(duration_s - CLIP_S, duration_s * 0.6))\n",
        "    start = int(t_s * SR)\n",
        "    end = min(len(wave), start + len(clip))\n",
        "    clip = clip[:end - start]\n",
        "\n",
        "    bg_seg = wave[start:end].copy()\n",
        "    clip2 = _mix_at_snr(bg_seg, clip, inject_snr_db)\n",
        "\n",
        "    wave2 = wave.copy()\n",
        "    wave2[start:end] = np.clip(wave2[start:end] + clip2, -1.0, 1.0)\n",
        "\n",
        "    a = {\n",
        "        \"t_start\": start / SR,\n",
        "        \"t_end\": end / SR,\n",
        "        \"category\": str(row[\"category\"]),\n",
        "        \"kind\": \"emergency\",\n",
        "        \"snr_db\": float(inject_snr_db),\n",
        "        \"forced\": True,\n",
        "    }\n",
        "    ann2 = sorted(ann + [a], key=lambda d: d[\"t_start\"])\n",
        "    return wave2, ann2\n",
        "\n",
        "def build_gt_emergency_windows_soundscape(ann, duration_s, decision_hop_s, win_s):\n",
        "    # positive if overlaps trailing window [t-win_s, t]\n",
        "    times = np.arange(decision_hop_s, duration_s + 1e-6, decision_hop_s)\n",
        "    y = np.zeros(len(times), dtype=np.int64)\n",
        "    for i, t in enumerate(times):\n",
        "        w0, w1 = t - win_s, t\n",
        "        for a in ann:\n",
        "            if a.get(\"kind\") != \"emergency\":\n",
        "                continue\n",
        "            if not (a[\"t_end\"] <= w0 or a[\"t_start\"] >= w1):\n",
        "                y[i] = 1\n",
        "                break\n",
        "    return times, y\n",
        "\n",
        "def get_trailing_window(wave, t_end_s, win_s):\n",
        "    end = int(t_end_s * SR)\n",
        "    win_T = int(win_s * SR)\n",
        "    start = end - win_T\n",
        "    if start < 0:\n",
        "        seg = np.pad(wave[:end], (abs(start), 0))\n",
        "    else:\n",
        "        seg = wave[start:end]\n",
        "    if len(seg) < win_T:\n",
        "        seg = np.pad(seg, (0, win_T - len(seg)))\n",
        "    return seg.astype(np.float32)\n",
        "\n",
        "def stage1_trigger_times(stage1_gate, wave_32k):\n",
        "    trig_hops, hop_s = stage1_gate.run(wave_32k)\n",
        "    idx = np.where(trig_hops)[0]\n",
        "    # end-of-frame time to reduce alignment misses\n",
        "    frame_s = stage1_gate.cfg.frame_s\n",
        "    trig_times = (idx * hop_s + frame_s).astype(np.float32)\n",
        "    return trig_times, hop_s, len(trig_hops)\n",
        "\n",
        "def gate_open_mask(decision_times, trig_times, hold_s):\n",
        "    if trig_times is None or len(trig_times)==0:\n",
        "        return np.zeros(len(decision_times), dtype=np.bool_)\n",
        "    mask = np.zeros(len(decision_times), dtype=np.bool_)\n",
        "    for i, t in enumerate(decision_times):\n",
        "        w0, w1 = t - hold_s, t\n",
        "        i0 = np.searchsorted(trig_times, w0, side=\"left\")\n",
        "        i1 = np.searchsorted(trig_times, w1, side=\"right\")\n",
        "        mask[i] = (i1 > i0)\n",
        "    return mask\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_soundscape_pipeline_smoke(wave, ann, pipeline, cfg: EvalConfig,\n",
        "                                 stage1_gate=None,\n",
        "                                 stage2_type=None, stage2_name=None,\n",
        "                                 bc_frontend=None, bc_model=None):\n",
        "    duration_s = len(wave) / SR\n",
        "    decision_times, y_true = build_gt_emergency_windows_soundscape(\n",
        "        ann, duration_s, cfg.decision_hop_s, cfg.label_win_s\n",
        "    )\n",
        "\n",
        "    # stage1 gating\n",
        "    stage1_hops = 0\n",
        "    stage1_events = 0\n",
        "    open_mask = None\n",
        "    if stage1_gate is not None:\n",
        "        trig_times, s1_hop, stage1_hops = stage1_trigger_times(stage1_gate, wave)\n",
        "        stage1_events = int(len(trig_times))\n",
        "        open_mask = gate_open_mask(decision_times, trig_times, hold_s=cfg.label_win_s)\n",
        "\n",
        "    y_pred = np.zeros(len(decision_times), dtype=np.int64)\n",
        "    y_score = np.zeros(len(decision_times), dtype=np.float32)\n",
        "    n_s2 = 0\n",
        "    n_s3 = 0\n",
        "\n",
        "    em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "\n",
        "    for i, t in enumerate(decision_times):\n",
        "        run_s2 = False\n",
        "        run_s3 = False\n",
        "\n",
        "        if pipeline == \"S3\":\n",
        "            run_s3 = True\n",
        "        elif pipeline == \"S1+S3\":\n",
        "            run_s3 = bool(open_mask[i])\n",
        "        elif pipeline == \"S2+S3\":\n",
        "            run_s2 = True\n",
        "        elif pipeline == \"S1+S2+S3\":\n",
        "            run_s2 = bool(open_mask[i])\n",
        "        else:\n",
        "            raise ValueError(pipeline)\n",
        "\n",
        "        seg = get_trailing_window(wave, float(t), cfg.label_win_s)\n",
        "        x = torch.from_numpy(seg)[None, None, :].to(DEVICE)\n",
        "\n",
        "        if run_s2:\n",
        "            n_s2 += 1\n",
        "            if stage2_type == \"mn\":\n",
        "                pd = float(stage2_mn_pdanger(x).item())\n",
        "                mac_s2 = MACS_STAGE2_MN\n",
        "            else:\n",
        "                pd = float(bcresnet_predict_pdanger(bc_frontend, bc_model, x[:,0,:]).item())\n",
        "                mac_s2 = MACS_STAGE2_BC\n",
        "            y_score[i] = pd\n",
        "\n",
        "            escalate = (pd >= cfg.stage2_gate)\n",
        "            if cfg.stage2_uncert_lo is not None and cfg.stage2_uncert_hi is not None:\n",
        "                escalate = escalate or (cfg.stage2_uncert_lo <= pd <= cfg.stage2_uncert_hi)\n",
        "\n",
        "            run_s3 = escalate\n",
        "        else:\n",
        "            mac_s2 = 0.0\n",
        "\n",
        "        if run_s3:\n",
        "            n_s3 += 1\n",
        "            # predict class\n",
        "            t_hat = int(stage3_predict_target(x).item())\n",
        "            cat = target_to_cat[t_hat]\n",
        "            y_pred[i] = 1 if cat in EMERGENCY_CATS else 0\n",
        "\n",
        "            # if no stage2 score, use stage3 emergency prob mass\n",
        "            if not run_s2:\n",
        "                xm = wave_to_mel_128(mel128, x)\n",
        "                logits = dymn_50(xm)[0]  # (1,50)\n",
        "                p = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
        "                y_score[i] = float(p[em_targets].sum())\n",
        "\n",
        "    # metrics\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "\n",
        "    # TR/DER\n",
        "    tr = float(stage1_events / max(1, stage1_hops)) if stage1_gate is not None else float(\"nan\")\n",
        "    if stage1_gate is not None:\n",
        "        der = float(n_s3 / max(1, stage1_events))\n",
        "    else:\n",
        "        der = float(n_s3 / max(1, len(decision_times)))\n",
        "\n",
        "    # compute\n",
        "    if stage2_type == \"mn\":\n",
        "        mac_s2_call = MACS_STAGE2_MN\n",
        "    elif stage2_type == \"bc\":\n",
        "        mac_s2_call = MACS_STAGE2_BC\n",
        "    else:\n",
        "        mac_s2_call = 0.0\n",
        "\n",
        "    cavg = compute_cavg_macs(\n",
        "        duration_s=duration_s,\n",
        "        n_stage1_calls=(stage1_hops if stage1_gate is not None else 0),\n",
        "        n_stage2_calls=n_s2,\n",
        "        n_stage3_calls=n_s3,\n",
        "        mac_stage1_per_call=MAC_STAGE1_PER_CALL,\n",
        "        mac_stage2_per_call=mac_s2_call,\n",
        "        mac_stage3_per_call=MACS_STAGE3_DYMN,\n",
        "    )\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"TR\": tr, \"DER\": der,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": float(stage1_hops if stage1_gate is not None else 0),\n",
        "        \"Stage2_calls\": float(n_s2),\n",
        "        \"Stage3_calls\": float(n_s3),\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn,\n",
        "        \"stage2_name\": stage2_name or \"\",\n",
        "        \"Stage1\": (S1_SMOKE_NAME if stage1_gate is not None else \"\")\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# Build smoke eval df (balanced)\n",
        "# ============================================================\n",
        "df_pos = df[df[\"is_emergency\"] == 1]\n",
        "df_neg = df[df[\"is_emergency\"] == 0]\n",
        "n_pos = min(16, len(df_pos))\n",
        "n_neg = min(16, len(df_neg))\n",
        "assert n_pos > 0 and n_neg > 0, \"Need both emergency and non-emergency clips for smoke.\"\n",
        "\n",
        "df_eval_smoke = pd.concat(\n",
        "    [df_pos.sample(n=n_pos, random_state=SMOKE_SEED),\n",
        "     df_neg.sample(n=n_neg, random_state=SMOKE_SEED)],\n",
        "    ignore_index=True\n",
        ").sample(frac=1.0, random_state=SMOKE_SEED).reset_index(drop=True).iloc[:SMOKE_N_CLIPS].copy()\n",
        "\n",
        "print(f\"[SMOKE] df_eval_smoke: {len(df_eval_smoke)} | emergency: {int(df_eval_smoke['is_emergency'].sum())} | non-em: {int((df_eval_smoke['is_emergency']==0).sum())}\")\n",
        "\n",
        "# ============================================================\n",
        "# Pick 1 scenario @ 60s\n",
        "# ============================================================\n",
        "SCENARIOS_SMOKE = []\n",
        "for s in SCENARIOS[:SMOKE_SCENARIOS]:\n",
        "    SCENARIOS_SMOKE.append(ScenarioConfig(**{**s.__dict__, \"duration_s\": SMOKE_DURATION_S}))\n",
        "scen = SCENARIOS_SMOKE[0]\n",
        "print(\"[SMOKE] Scenario:\", scen.name, scen.duration_s, \"seconds\")\n",
        "\n",
        "# ============================================================\n",
        "# Load BC tau=8\n",
        "# ============================================================\n",
        "bc_name = \"bcresnet_tau8\"\n",
        "assert bc_name in BCRESNET_CKPTS, f\"BCRESNET_CKPTS missing key: {bc_name}\"\n",
        "tau8, fe8, m8 = load_bcresnet_binary(BCRESNET_CKPTS[bc_name], device=DEVICE)\n",
        "print(\"[SMOKE] Loaded\", bc_name, \"tau =\", tau8)\n",
        "\n",
        "# Quick forward sanity\n",
        "x0 = _to_wave_tensor_from_filename(df_eval_smoke.loc[0, \"filename\"])\n",
        "p_mn = float(stage2_mn_pdanger(x0).item())\n",
        "p_bc = float(bcresnet_predict_pdanger(fe8, m8, x0[:,0,:]).item())\n",
        "t0 = int(stage3_predict_target(x0).item())\n",
        "print(\"[SMOKE] MN p(danger):\", p_mn)\n",
        "print(\"[SMOKE] BC p(danger):\", p_bc)\n",
        "print(\"[SMOKE] DyMN pred target:\", t0, \"| cat:\", target_to_cat[t0])\n",
        "\n",
        "# ============================================================\n",
        "# RUN SMOKE EXPERIMENTS\n",
        "# ============================================================\n",
        "smoke_results = []\n",
        "\n",
        "# (1) Stage3 single clips\n",
        "r = stage3_single_clips_smoke(df_eval_smoke, batch_size=16)\n",
        "r.update({\"Experiment\": \"SMOKE_Stage3_single_clips\", \"Scenario\": \"\", \"stage2_name\": \"\"})\n",
        "smoke_results.append(r)\n",
        "print(\"[SMOKE] OK Stage3 single clips | EF1:\", r[\"EF1\"], \"| Cavg:\", r[\"Cavg_MACs_per_s\"])\n",
        "\n",
        "# (2) Stage2+Stage3 single clips (MN)\n",
        "r = stage2_stage3_single_clips_smoke(df_eval_smoke, \"mn04_binary\", \"mn\", EVAL_CFG_SMOKE)\n",
        "r.update({\"Experiment\": \"SMOKE_Stage2+Stage3_single_clips\", \"Scenario\": \"\"})\n",
        "smoke_results.append(r)\n",
        "print(\"[SMOKE] OK MN S2+S3 clips | EF1:\", r[\"EF1\"], \"| S3 calls:\", r[\"Stage3_calls\"], \"| Cavg:\", r[\"Cavg_MACs_per_s\"])\n",
        "\n",
        "# (2b) Stage2+Stage3 single clips (BC tau8)\n",
        "r = stage2_stage3_single_clips_smoke(df_eval_smoke, bc_name, \"bc\", EVAL_CFG_SMOKE, bc_frontend=fe8, bc_model=m8)\n",
        "r.update({\"Experiment\": \"SMOKE_Stage2+Stage3_single_clips\", \"Scenario\": \"\"})\n",
        "smoke_results.append(r)\n",
        "print(\"[SMOKE] OK BC S2+S3 clips | EF1:\", r[\"EF1\"], \"| S3 calls:\", r[\"Stage3_calls\"], \"| Cavg:\", r[\"Cavg_MACs_per_s\"])\n",
        "\n",
        "# (3) Build 60s soundscape + force >=1 emergency (high SNR so Stage1 sees it)\n",
        "wave_sc, ann_sc = build_soundscape(scen, seed=2026)\n",
        "wave_sc, ann_sc = ensure_min_emergencies_soundscape(wave_sc, ann_sc, scen.duration_s, min_emerg=1, seed=999, inject_snr_db=12.0)\n",
        "\n",
        "print(\"[SMOKE] Soundscape:\", scen.name,\n",
        "      \"len(s)=\", len(wave_sc)/SR,\n",
        "      \"events=\", len(ann_sc),\n",
        "      \"emerg=\", sum(1 for a in ann_sc if a.get(\"kind\")==\"emergency\"))\n",
        "\n",
        "# Optional: show emergency interval(s)\n",
        "em = [a for a in ann_sc if a.get(\"kind\")==\"emergency\"]\n",
        "print(\"[SMOKE] Emergency intervals:\", [(a[\"t_start\"], a[\"t_end\"], a.get(\"category\"), a.get(\"snr_db\"), a.get(\"forced\")) for a in em])\n",
        "\n",
        "PIPELINES = [\n",
        "    (\"S3\",       None,                 None),\n",
        "    (\"S1+S3\",    S1_SMOKE_GATE,         None),\n",
        "    (\"S2+S3\",    None,                 (\"mn04_binary\", \"mn\")),\n",
        "    (\"S1+S2+S3\", S1_SMOKE_GATE,        (\"mn04_binary\", \"mn\")),\n",
        "]\n",
        "\n",
        "for pipe, gate, s2 in PIPELINES:\n",
        "    if s2 is None:\n",
        "        rr = run_soundscape_pipeline_smoke(\n",
        "            wave_sc, ann_sc,\n",
        "            pipeline=pipe,\n",
        "            cfg=EVAL_CFG_SMOKE,\n",
        "            stage1_gate=gate,\n",
        "            stage2_type=None,\n",
        "            stage2_name=None\n",
        "        )\n",
        "    else:\n",
        "        s2_name, s2_type = s2\n",
        "        rr = run_soundscape_pipeline_smoke(\n",
        "            wave_sc, ann_sc,\n",
        "            pipeline=pipe,\n",
        "            cfg=EVAL_CFG_SMOKE,\n",
        "            stage1_gate=gate,\n",
        "            stage2_type=s2_type,\n",
        "            stage2_name=s2_name\n",
        "        )\n",
        "\n",
        "    rr.update({\"Experiment\": f\"SMOKE_{pipe}\", \"Scenario\": scen.name})\n",
        "    smoke_results.append(rr)\n",
        "\n",
        "    print(f\"[SMOKE] OK {pipe:8s} | EF1={rr['EF1']:.3f} AUROC={rr['AUROC']:.3f} \"\n",
        "          f\"TR={rr['TR'] if not np.isnan(rr['TR']) else float('nan'):.4f} DER={rr['DER']:.4f} \"\n",
        "          f\"Cavg={rr['Cavg_MACs_per_s']:.2e} | calls S1/S2/S3 = {rr['Stage1_calls']:.0f}/{rr['Stage2_calls']:.0f}/{rr['Stage3_calls']:.0f}\")\n",
        "\n",
        "# ============================================================\n",
        "# SAVE + SHOW TABLE\n",
        "# ============================================================\n",
        "smoke_df = pd.DataFrame(smoke_results)\n",
        "\n",
        "cols = [\n",
        "    \"Experiment\", \"Scenario\", \"Stage1\", \"stage2_name\", \"pipeline\",\n",
        "    \"EF1\", \"Prec\", \"Rec\", \"AUROC\",\n",
        "    \"TR\", \"DER\",\n",
        "    \"Cavg_MACs_per_s\", \"EUI\",\n",
        "    \"Stage1_calls\", \"Stage2_calls\", \"Stage3_calls\",\n",
        "    \"Top1_Acc\",\n",
        "    \"TP\", \"FP\", \"FN\"\n",
        "]\n",
        "for c in cols:\n",
        "    if c not in smoke_df.columns:\n",
        "        smoke_df[c] = np.nan\n",
        "smoke_df = smoke_df[cols]\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "smoke_path = os.path.join(OUT_DIR, \"smoke_results.csv\")\n",
        "smoke_df.to_csv(smoke_path, index=False)\n",
        "print(\"[SMOKE] Saved:\", smoke_path)\n",
        "\n",
        "smoke_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vfKXxlzoiakV",
        "outputId": "2239c88f-90eb-4fcc-df6a-b210c8c0836a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BIG] df_eval: 2000 | emergencies: 320\n",
            "[BIG] Loaded BCResNet variants: ['bcresnet_tau1', 'bcresnet_tau3', 'bcresnet_tau8']\n",
            "[BIG] Stage2 models: ['mn04_binary', 'bcresnet_tau1', 'bcresnet_tau3', 'bcresnet_tau8']\n",
            "[BIG] OK Stage3_single_clips | EF1: 0.9859154929572433 | Cavg: 11607404.8\n",
            "[BIG] OK S2+S3 clips: mn04_binary | EF1: 0.9905956112847633 | S3 calls: 331.0 | Cavg: 15007156.6944\n",
            "[BIG] OK S2+S3 clips: bcresnet_tau1 | EF1: 0.9579288025884942 | S3 calls: 820.0 | Cavg: 8363443.168\n",
            "[BIG] OK S2+S3 clips: bcresnet_tau3 | EF1: 0.891566265059743 | S3 calls: 550.0 | Cavg: 6796443.52\n",
            "[BIG] OK S2+S3 clips: bcresnet_tau8 | EF1: 0.9648562300314459 | S3 calls: 1018.0 | Cavg: 9512576.2432\n",
            "[BIG] OK S3 soundscape: quiet_home_day | EF1: 0.5147058823524405 | S3 rate: 1.0\n",
            "[BIG] OK S3 soundscape: sleep_night | EF1: 0.499999999999475 | S3 rate: 1.0\n",
            "[BIG] OK S3 soundscape: busy_indoor | EF1: 0.36496350364913743 | S3 rate: 1.0\n",
            "[BIG] OK S3 soundscape: kitchen_like | EF1: 0.3235294117642811 | S3 rate: 1.0\n",
            "[BIG] OK S3 soundscape: outdoor_park | EF1: 0.703030303029795 | S3 rate: 1.0\n",
            "[BIG] OK S3 soundscape: commute_like | EF1: 0.0533333333329408 | S3 rate: 1.0\n",
            "[BIG] Done. Total rows: 125\n",
            "[BIG] Saved: /content/echo_guard_runs/results_summary.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 125,\n  \"fields\": [\n    {\n      \"column\": \"Experiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Stage1+Stage2+Stage3_soundscapes\",\n          \"Stage1+Stage3_soundscapes\",\n          \"Stage3_soundscapes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scenario\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"busy_indoor\",\n          \"commute_like\",\n          \"sleep_night\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"S1_B_energy_flux\",\n          \"\",\n          \"S1_A_energy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stage2_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"bcresnet_tau1\",\n          \"\",\n          \"bcresnet_tau8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pipeline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"S1+S2+S3\",\n          \"S1+S3\",\n          \"S3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EF1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27148724504496224,\n        \"min\": 0.0,\n        \"max\": 0.9905956112847633,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.5054945054940451,\n          0.36496350364913743,\n          0.15384615384600708\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3982649093059187,\n        \"min\": 0.0,\n        \"max\": 0.9999999999999667,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.7419354838709439,\n          0.32467532467532045,\n          0.9999999999997999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24884318573669392,\n        \"min\": 0.0,\n        \"max\": 0.9874999999999968,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          0.8093749999999974,\n          0.1124999999999986,\n          0.7124999999999911\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUROC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17234827619224122,\n        \"min\": 0.07114406779661017,\n        \"max\": 0.9998307291666667,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          0.7896052631578947,\n          0.717595029239766,\n          0.5516374269005848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.67561391473558,\n        \"min\": 0.2,\n        \"max\": 95.7,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          2.2,\n          2.8,\n          1.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27029955803471606,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          0.0575,\n          0.24166666666666667,\n          0.018333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TTD_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.53816788832341,\n        \"min\": 0.43400000000000105,\n        \"max\": 296.64806250000004,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          41.43834375,\n          6.009749999999997,\n          77.14806250000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cavg_MACs_per_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42715982.20858641,\n        \"min\": 1897467.52,\n        \"max\": 135020632.05333334,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          56720080.333333336,\n          116714046.66666667,\n          9644904.146666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EUI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.728209211863335e-08,\n        \"min\": 0.0,\n        \"max\": 3.513454958460516e-07,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          7.133564392934253e-09,\n          5.811225417922479e-09,\n          1.2432861152302103e-09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage1_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5405.611511765256,\n        \"min\": 0.0,\n        \"max\": 11991.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          11991.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage2_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 575.9078355924447,\n        \"min\": 0.0,\n        \"max\": 2000.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          142.0,\n          1199.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage3_calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 367.85391174635726,\n        \"min\": 0.0,\n        \"max\": 2000.0,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          27.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Top1_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.985,\n        \"max\": 0.985,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "res_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-68ebd752-d2ab-4fe7-bf37-7b4a5d229d33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Experiment</th>\n",
              "      <th>Scenario</th>\n",
              "      <th>Stage1</th>\n",
              "      <th>stage2_name</th>\n",
              "      <th>pipeline</th>\n",
              "      <th>EF1</th>\n",
              "      <th>Prec</th>\n",
              "      <th>Rec</th>\n",
              "      <th>AUROC</th>\n",
              "      <th>TR</th>\n",
              "      <th>DER</th>\n",
              "      <th>TTD_sec</th>\n",
              "      <th>Cavg_MACs_per_s</th>\n",
              "      <th>EUI</th>\n",
              "      <th>Stage1_calls</th>\n",
              "      <th>Stage2_calls</th>\n",
              "      <th>Stage3_calls</th>\n",
              "      <th>Top1_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.551389</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>5.485584e+06</td>\n",
              "      <td>2.804554e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.550965</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.014167</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>6.646325e+06</td>\n",
              "      <td>2.735620e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.553319</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.014167</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>7.787720e+06</td>\n",
              "      <td>2.334678e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.556579</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>6.626980e+06</td>\n",
              "      <td>2.321512e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.551637</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>9.644904e+06</td>\n",
              "      <td>1.777400e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.556418</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.056667</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>1.272087e+07</td>\n",
              "      <td>1.550076e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.697376</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>1.438344</td>\n",
              "      <td>2.423155e+07</td>\n",
              "      <td>1.338438e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.320988</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.699817</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.055833</td>\n",
              "      <td>1.438344</td>\n",
              "      <td>2.403809e+07</td>\n",
              "      <td>1.335329e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.553874</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>1.689908e+07</td>\n",
              "      <td>1.059847e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.559561</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>41.438344</td>\n",
              "      <td>2.104302e+07</td>\n",
              "      <td>8.511348e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.288660</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.717595</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.201667</td>\n",
              "      <td>1.438344</td>\n",
              "      <td>4.096556e+07</td>\n",
              "      <td>7.046402e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>busy_indoor</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.342105</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.721338</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.025833</td>\n",
              "      <td>1.438344</td>\n",
              "      <td>6.480392e+07</td>\n",
              "      <td>5.279083e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.766610</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.126667</td>\n",
              "      <td>9.148063</td>\n",
              "      <td>3.042777e+07</td>\n",
              "      <td>3.206314e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.766314</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.018333</td>\n",
              "      <td>9.148063</td>\n",
              "      <td>5.728125e+07</td>\n",
              "      <td>2.909620e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.469492</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.588406e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.469492</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.003333</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>3.286285e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.469492</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>3.576470e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_A_energy</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.469492</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.018333</td>\n",
              "      <td>296.648063</td>\n",
              "      <td>5.027396e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431780</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>192.148063</td>\n",
              "      <td>1.848741e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431780</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>6.539924e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431780</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.010833</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>6.830109e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431780</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.044167</td>\n",
              "      <td>192.148063</td>\n",
              "      <td>1.069924e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>2.036802e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>commute_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.734661</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.065833</td>\n",
              "      <td>116.648063</td>\n",
              "      <td>2.336660e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau3</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.897564</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.018333</td>\n",
              "      <td>1.509750</td>\n",
              "      <td>6.409085e+06</td>\n",
              "      <td>6.826247e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.901631</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>1.509750</td>\n",
              "      <td>8.246924e+06</td>\n",
              "      <td>6.062867e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>mn04_binary</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.889597</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>1.509750</td>\n",
              "      <td>1.447531e+07</td>\n",
              "      <td>4.287919e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_B_energy_flux</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.880445</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.059167</td>\n",
              "      <td>1.509750</td>\n",
              "      <td>1.114878e+07</td>\n",
              "      <td>4.036318e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau1</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.834703</td>\n",
              "      <td>55.9</td>\n",
              "      <td>0.129167</td>\n",
              "      <td>1.509750</td>\n",
              "      <td>4.465499e+07</td>\n",
              "      <td>1.033565e-08</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>963.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Stage1+Stage2+Stage3_soundscapes</td>\n",
              "      <td>kitchen_like</td>\n",
              "      <td>S1_C_sleep_aware</td>\n",
              "      <td>bcresnet_tau8</td>\n",
              "      <td>S1+S2+S3</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666398</td>\n",
              "      <td>55.9</td>\n",
              "      <td>0.246667</td>\n",
              "      <td>1.009750</td>\n",
              "      <td>5.829369e+07</td>\n",
              "      <td>7.458485e-09</td>\n",
              "      <td>11991.0</td>\n",
              "      <td>963.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68ebd752-d2ab-4fe7-bf37-7b4a5d229d33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68ebd752-d2ab-4fe7-bf37-7b4a5d229d33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68ebd752-d2ab-4fe7-bf37-7b4a5d229d33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                           Experiment      Scenario            Stage1  \\\n",
              "55   Stage1+Stage2+Stage3_soundscapes   busy_indoor       S1_A_energy   \n",
              "54   Stage1+Stage2+Stage3_soundscapes   busy_indoor       S1_A_energy   \n",
              "58   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_B_energy_flux   \n",
              "59   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_B_energy_flux   \n",
              "56   Stage1+Stage2+Stage3_soundscapes   busy_indoor       S1_A_energy   \n",
              "60   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_B_energy_flux   \n",
              "63   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_C_sleep_aware   \n",
              "62   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_C_sleep_aware   \n",
              "53   Stage1+Stage2+Stage3_soundscapes   busy_indoor       S1_A_energy   \n",
              "57   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_B_energy_flux   \n",
              "64   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_C_sleep_aware   \n",
              "61   Stage1+Stage2+Stage3_soundscapes   busy_indoor  S1_C_sleep_aware   \n",
              "124  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_C_sleep_aware   \n",
              "121  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_C_sleep_aware   \n",
              "113  Stage1+Stage2+Stage3_soundscapes  commute_like       S1_A_energy   \n",
              "114  Stage1+Stage2+Stage3_soundscapes  commute_like       S1_A_energy   \n",
              "115  Stage1+Stage2+Stage3_soundscapes  commute_like       S1_A_energy   \n",
              "116  Stage1+Stage2+Stage3_soundscapes  commute_like       S1_A_energy   \n",
              "117  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_B_energy_flux   \n",
              "118  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_B_energy_flux   \n",
              "119  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_B_energy_flux   \n",
              "120  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_B_energy_flux   \n",
              "122  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_C_sleep_aware   \n",
              "123  Stage1+Stage2+Stage3_soundscapes  commute_like  S1_C_sleep_aware   \n",
              "79   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_B_energy_flux   \n",
              "78   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_B_energy_flux   \n",
              "77   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_B_energy_flux   \n",
              "80   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_B_energy_flux   \n",
              "82   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_C_sleep_aware   \n",
              "84   Stage1+Stage2+Stage3_soundscapes  kitchen_like  S1_C_sleep_aware   \n",
              "\n",
              "       stage2_name  pipeline       EF1      Prec       Rec     AUROC    TR  \\\n",
              "55   bcresnet_tau3  S1+S2+S3  0.153846  1.000000  0.083333  0.551389   2.2   \n",
              "54   bcresnet_tau1  S1+S2+S3  0.181818  1.000000  0.100000  0.550965   2.2   \n",
              "58   bcresnet_tau1  S1+S2+S3  0.181818  1.000000  0.100000  0.553319   2.8   \n",
              "59   bcresnet_tau3  S1+S2+S3  0.153846  1.000000  0.083333  0.556579   2.8   \n",
              "56   bcresnet_tau8  S1+S2+S3  0.171429  0.600000  0.100000  0.551637   2.2   \n",
              "60   bcresnet_tau8  S1+S2+S3  0.197183  0.636364  0.116667  0.556418   2.8   \n",
              "63   bcresnet_tau3  S1+S2+S3  0.324324  0.857143  0.200000  0.697376  12.3   \n",
              "62   bcresnet_tau1  S1+S2+S3  0.320988  0.619048  0.216667  0.699817  12.3   \n",
              "53     mn04_binary  S1+S2+S3  0.179104  0.857143  0.100000  0.553874   2.2   \n",
              "57     mn04_binary  S1+S2+S3  0.179104  0.857143  0.100000  0.559561   2.8   \n",
              "64   bcresnet_tau8  S1+S2+S3  0.288660  0.378378  0.233333  0.717595  12.3   \n",
              "61     mn04_binary  S1+S2+S3  0.342105  0.812500  0.216667  0.721338  12.3   \n",
              "124  bcresnet_tau8  S1+S2+S3  0.097561  0.095238  0.100000  0.766610   8.7   \n",
              "121    mn04_binary  S1+S2+S3  0.166667  0.500000  0.100000  0.766314   8.7   \n",
              "113    mn04_binary  S1+S2+S3  0.000000  0.000000  0.000000  0.469492   0.7   \n",
              "114  bcresnet_tau1  S1+S2+S3  0.000000  0.000000  0.000000  0.469492   0.7   \n",
              "115  bcresnet_tau3  S1+S2+S3  0.000000  0.000000  0.000000  0.469492   0.7   \n",
              "116  bcresnet_tau8  S1+S2+S3  0.000000  0.000000  0.000000  0.469492   0.7   \n",
              "117    mn04_binary  S1+S2+S3  0.000000  0.000000  0.000000  0.431780   1.9   \n",
              "118  bcresnet_tau1  S1+S2+S3  0.000000  0.000000  0.000000  0.431780   1.9   \n",
              "119  bcresnet_tau3  S1+S2+S3  0.000000  0.000000  0.000000  0.431780   1.9   \n",
              "120  bcresnet_tau8  S1+S2+S3  0.000000  0.000000  0.000000  0.431780   1.9   \n",
              "122  bcresnet_tau1  S1+S2+S3  0.000000  0.000000  0.000000  0.607500   8.7   \n",
              "123  bcresnet_tau3  S1+S2+S3  0.000000  0.000000  0.000000  0.734661   8.7   \n",
              "79   bcresnet_tau3  S1+S2+S3  0.437500  0.583333  0.350000  0.897564   2.1   \n",
              "78   bcresnet_tau1  S1+S2+S3  0.500000  0.562500  0.450000  0.901631   2.1   \n",
              "77     mn04_binary  S1+S2+S3  0.620690  1.000000  0.450000  0.889597   2.1   \n",
              "80   bcresnet_tau8  S1+S2+S3  0.450000  0.450000  0.450000  0.880445   2.1   \n",
              "82   bcresnet_tau1  S1+S2+S3  0.461538  0.473684  0.450000  0.834703  55.9   \n",
              "84   bcresnet_tau8  S1+S2+S3  0.434783  0.384615  0.500000  0.666398  55.9   \n",
              "\n",
              "          DER     TTD_sec  Cavg_MACs_per_s           EUI  Stage1_calls  \\\n",
              "55   0.004167   41.438344     5.485584e+06  2.804554e-08       11991.0   \n",
              "54   0.014167   41.438344     6.646325e+06  2.735620e-08       11991.0   \n",
              "58   0.014167   41.438344     7.787720e+06  2.334678e-08       11991.0   \n",
              "59   0.004167   41.438344     6.626980e+06  2.321512e-08       11991.0   \n",
              "56   0.040000   41.438344     9.644904e+06  1.777400e-08       11991.0   \n",
              "60   0.056667   41.438344     1.272087e+07  1.550076e-08       11991.0   \n",
              "63   0.057500    1.438344     2.423155e+07  1.338438e-08       11991.0   \n",
              "62   0.055833    1.438344     2.403809e+07  1.335329e-08       11991.0   \n",
              "53   0.005833   41.438344     1.689908e+07  1.059847e-08       11991.0   \n",
              "57   0.005833   41.438344     2.104302e+07  8.511348e-09       11991.0   \n",
              "64   0.201667    1.438344     4.096556e+07  7.046402e-09       11991.0   \n",
              "61   0.025833    1.438344     6.480392e+07  5.279083e-09       11991.0   \n",
              "124  0.126667    9.148063     3.042777e+07  3.206314e-09       11991.0   \n",
              "121  0.018333    9.148063     5.728125e+07  2.909620e-09       11991.0   \n",
              "113  0.000000         NaN     8.588406e+06  0.000000e+00       11991.0   \n",
              "114  0.003333  116.648063     3.286285e+06  0.000000e+00       11991.0   \n",
              "115  0.005833  116.648063     3.576470e+06  0.000000e+00       11991.0   \n",
              "116  0.018333  296.648063     5.027396e+06  0.000000e+00       11991.0   \n",
              "117  0.001667  192.148063     1.848741e+07  0.000000e+00       11991.0   \n",
              "118  0.008333  116.648063     6.539924e+06  0.000000e+00       11991.0   \n",
              "119  0.010833  116.648063     6.830109e+06  0.000000e+00       11991.0   \n",
              "120  0.044167  192.148063     1.069924e+07  0.000000e+00       11991.0   \n",
              "122  0.040000  116.648063     2.036802e+07  0.000000e+00       11991.0   \n",
              "123  0.065833  116.648063     2.336660e+07  0.000000e+00       11991.0   \n",
              "79   0.018333    1.509750     6.409085e+06  6.826247e-08       11991.0   \n",
              "78   0.034167    1.509750     8.246924e+06  6.062867e-08       11991.0   \n",
              "77   0.007500    1.509750     1.447531e+07  4.287919e-08       11991.0   \n",
              "80   0.059167    1.509750     1.114878e+07  4.036318e-08       11991.0   \n",
              "82   0.129167    1.509750     4.465499e+07  1.033565e-08       11991.0   \n",
              "84   0.246667    1.009750     5.829369e+07  7.458485e-09       11991.0   \n",
              "\n",
              "     Stage2_calls  Stage3_calls  Top1_Acc  \n",
              "55          142.0           5.0       NaN  \n",
              "54          142.0          17.0       NaN  \n",
              "58          180.0          17.0       NaN  \n",
              "59          180.0           5.0       NaN  \n",
              "56          142.0          48.0       NaN  \n",
              "60          180.0          68.0       NaN  \n",
              "63          560.0          69.0       NaN  \n",
              "62          560.0          67.0       NaN  \n",
              "53          142.0           7.0       NaN  \n",
              "57          180.0           7.0       NaN  \n",
              "64          560.0         242.0       NaN  \n",
              "61          560.0          31.0       NaN  \n",
              "124         499.0         152.0       NaN  \n",
              "121         499.0          22.0       NaN  \n",
              "113          72.0           0.0       NaN  \n",
              "114          72.0           4.0       NaN  \n",
              "115          72.0           7.0       NaN  \n",
              "116          72.0          22.0       NaN  \n",
              "117         161.0           2.0       NaN  \n",
              "118         161.0          10.0       NaN  \n",
              "119         161.0          13.0       NaN  \n",
              "120         161.0          53.0       NaN  \n",
              "122         499.0          48.0       NaN  \n",
              "123         499.0          79.0       NaN  \n",
              "79          118.0          22.0       NaN  \n",
              "78          118.0          41.0       NaN  \n",
              "77          118.0           9.0       NaN  \n",
              "80          118.0          71.0       NaN  \n",
              "82          963.0         155.0       NaN  \n",
              "84          963.0         296.0       NaN  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# BIG RUN\n",
        "# - Uses the SAME semantics as the smoke run:\n",
        "#   * Soundscape GT positives: trailing window [t-LABEL_WIN_S, t] overlaps any emergency\n",
        "#   * Model input on soundscapes: trailing window of length LABEL_WIN_S (== CLIP_S)\n",
        "#   * Stage1 trigger time = end-of-frame; gate hold = LABEL_WIN_S\n",
        "#   * No recursion; no reliance on old run_single_clip_stage2_stage3\n",
        "# - Experiments:\n",
        "#   1) Stage3 (single ESC-50 clips)\n",
        "#   2) Stage2 + Stage3 (single ESC-50 clips) for MN + all BC taus\n",
        "#   3) Soundscapes: S3, S1+S3, S2+S3, S1+S2+S3 across scenarios, Stage1 variants, Stage2 variants\n",
        "# - Output: OUT_DIR/results_summary.csv\n",
        "# ============================================================\n",
        "\n",
        "import os, warnings, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -----------------------------\n",
        "# (optional) silence EfficientAT warning\n",
        "# -----------------------------\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*autocast.*deprecated.*\")\n",
        "\n",
        "# -----------------------------\n",
        "# Safety checks (must exist from earlier cells)\n",
        "# -----------------------------\n",
        "needed = [\n",
        "    \"df\", \"ESC50_32K_ROOT\", \"resolve_audio_path\", \"load_audio_32k_5s\", \"SR\", \"CLIP_T\", \"CLIP_S\",\n",
        "    \"EMERGENCY_CATS\", \"target_to_cat\", \"cat_to_target\",\n",
        "    \"SCENARIOS\", \"ScenarioConfig\", \"build_soundscape\",\n",
        "    \"BCRESNET_CKPTS\", \"load_bcresnet_binary\", \"bcresnet_predict_pdanger\",\n",
        "    \"stage2_mn_pdanger\", \"stage3_predict_target\",\n",
        "    \"DSP_GATES\",  # dict: {name: DSPGate}\n",
        "    \"OUT_DIR\", \"DEVICE\",\n",
        "    \"MAC_STAGE1_PER_CALL\", \"MACS_STAGE2_MN\", \"MACS_STAGE2_BC\", \"MACS_STAGE3_DYMN\", \"compute_cavg_macs\",\n",
        "    \"mel128\", \"wave_to_mel_128\", \"dymn_50\"\n",
        "]\n",
        "missing = [x for x in needed if x not in globals()]\n",
        "assert not missing, f\"Missing definitions: {missing}\"\n",
        "\n",
        "# ============================================================\n",
        "# Config (match smoke semantics)\n",
        "# ============================================================\n",
        "class EvalConfig:\n",
        "    def __init__(self, decision_hop_s=0.5, label_win_s=5.0, stage2_gate=0.30, stage2_uncert_lo=0.25, stage2_uncert_hi=0.65):\n",
        "        self.decision_hop_s = decision_hop_s\n",
        "        self.label_win_s = label_win_s\n",
        "        self.stage2_gate = stage2_gate\n",
        "        self.stage2_uncert_lo = stage2_uncert_lo\n",
        "        self.stage2_uncert_hi = stage2_uncert_hi\n",
        "\n",
        "EVAL_CFG = EvalConfig(\n",
        "    decision_hop_s=0.5,\n",
        "    label_win_s=float(CLIP_S),  # critical alignment: window = model input = 5s\n",
        "    stage2_gate=0.30,\n",
        "    stage2_uncert_lo=0.25,\n",
        "    stage2_uncert_hi=0.65\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "SOUNDSCAPE_SEED_BASE = 2026\n",
        "\n",
        "# ============================================================\n",
        "# Helpers: metrics + IO\n",
        "# ============================================================\n",
        "def _prec_rec_f1(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = np.asarray(y_pred).astype(int)\n",
        "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
        "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
        "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec  = tp / (tp + fn + 1e-12)\n",
        "    f1   = 2 * prec * rec / (prec + rec + 1e-12)\n",
        "    return float(prec), float(rec), float(f1), tp, fp, fn\n",
        "\n",
        "def _auroc_rank(y_true, y_score):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_score = np.asarray(y_score).astype(float)\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return float(\"nan\")\n",
        "    pos = y_score[y_true==1]\n",
        "    neg = y_score[y_true==0]\n",
        "    if len(pos)==0 or len(neg)==0:\n",
        "        return float(\"nan\")\n",
        "    cnt = 0.0\n",
        "    for p in pos:\n",
        "        cnt += np.sum(p > neg) + 0.5*np.sum(p == neg)\n",
        "    return float(cnt / (len(pos)*len(neg)))\n",
        "\n",
        "def _to_wave_tensor_from_filename(fn: str) -> torch.Tensor:\n",
        "    p = resolve_audio_path(ESC50_32K_ROOT, fn)\n",
        "    w = load_audio_32k_5s(p)\n",
        "    assert w.shape == (CLIP_T,), f\"bad wave shape: {w.shape}\"\n",
        "    return torch.from_numpy(w)[None, None, :].to(DEVICE)\n",
        "\n",
        "def build_gt_emergency_windows_soundscape(ann, duration_s, decision_hop_s, win_s):\n",
        "    # positive if overlaps trailing window [t-win_s, t]\n",
        "    times = np.arange(decision_hop_s, duration_s + 1e-6, decision_hop_s)\n",
        "    y = np.zeros(len(times), dtype=np.int64)\n",
        "    for i, t in enumerate(times):\n",
        "        w0, w1 = t - win_s, t\n",
        "        for a in ann:\n",
        "            if a.get(\"kind\") != \"emergency\":\n",
        "                continue\n",
        "            if not (a[\"t_end\"] <= w0 or a[\"t_start\"] >= w1):\n",
        "                y[i] = 1\n",
        "                break\n",
        "    return times, y\n",
        "\n",
        "def get_trailing_window(wave, t_end_s, win_s):\n",
        "    end = int(t_end_s * SR)\n",
        "    win_T = int(win_s * SR)\n",
        "    start = end - win_T\n",
        "    if start < 0:\n",
        "        seg = np.pad(wave[:end], (abs(start), 0))\n",
        "    else:\n",
        "        seg = wave[start:end]\n",
        "    if len(seg) < win_T:\n",
        "        seg = np.pad(seg, (0, win_T - len(seg)))\n",
        "    return seg.astype(np.float32)\n",
        "\n",
        "def stage1_trigger_times(stage1_gate, wave_32k):\n",
        "    trig_hops, hop_s = stage1_gate.run(wave_32k)\n",
        "    idx = np.where(trig_hops)[0]\n",
        "    frame_s = stage1_gate.cfg.frame_s\n",
        "    trig_times = (idx * hop_s + frame_s).astype(np.float32)  # end-of-frame\n",
        "    return trig_times, hop_s, len(trig_hops), int(len(trig_times))\n",
        "\n",
        "def gate_open_mask(decision_times, trig_times, hold_s):\n",
        "    if trig_times is None or len(trig_times)==0:\n",
        "        return np.zeros(len(decision_times), dtype=np.bool_)\n",
        "    mask = np.zeros(len(decision_times), dtype=np.bool_)\n",
        "    for i, t in enumerate(decision_times):\n",
        "        w0, w1 = t - hold_s, t\n",
        "        i0 = np.searchsorted(trig_times, w0, side=\"left\")\n",
        "        i1 = np.searchsorted(trig_times, w1, side=\"right\")\n",
        "        mask[i] = (i1 > i0)\n",
        "    return mask\n",
        "\n",
        "# (Optional) time-to-detect: first decision time where pred=1 after the first emergency start\n",
        "def _ttd_seconds(ann, decision_times, y_pred):\n",
        "    em = [a for a in ann if a.get(\"kind\")==\"emergency\"]\n",
        "    if len(em)==0:\n",
        "        return float(\"nan\")\n",
        "    t0 = float(min(a[\"t_start\"] for a in em))\n",
        "    for t, yp in zip(decision_times, y_pred):\n",
        "        if t >= t0 and int(yp)==1:\n",
        "            return float(t - t0)\n",
        "    return float(\"nan\")\n",
        "\n",
        "# ============================================================\n",
        "# 1) Single-clip evaluators (Stage3, Stage2+Stage3)\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def eval_stage3_single_clips(df_eval: pd.DataFrame, batch_size: int = 64):\n",
        "    y_true = df_eval[\"is_emergency\"].astype(int).values\n",
        "    y_t_true = df_eval[\"target\"].astype(int).values\n",
        "    y_pred = []\n",
        "    y_score = []\n",
        "    y_t_pred = []\n",
        "\n",
        "    em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "\n",
        "    for i in range(0, len(df_eval), batch_size):\n",
        "        sub = df_eval.iloc[i:i+batch_size]\n",
        "        waves = []\n",
        "        for fn in sub[\"filename\"].values:\n",
        "            waves.append(load_audio_32k_5s(resolve_audio_path(ESC50_32K_ROOT, fn)))\n",
        "        x = torch.from_numpy(np.stack(waves))[:, None, :].to(DEVICE)  # (B,1,T)\n",
        "\n",
        "        xm = wave_to_mel_128(mel128, x)\n",
        "        logits = dymn_50(xm)[0]               # (B,50)\n",
        "        p = F.softmax(logits, dim=-1)         # (B,50)\n",
        "        p_np = p.detach().cpu().numpy()\n",
        "\n",
        "        pred_t = p_np.argmax(axis=-1)\n",
        "        y_t_pred.append(pred_t)\n",
        "\n",
        "        p_em = p_np[:, em_targets].sum(axis=-1)\n",
        "        y_score.append(p_em)\n",
        "        y_pred.append((p_em >= 0.5).astype(int))\n",
        "\n",
        "    y_pred = np.concatenate(y_pred)\n",
        "    y_score = np.concatenate(y_score)\n",
        "    y_t_pred = np.concatenate(y_t_pred)\n",
        "\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "    top1 = float((y_t_pred == y_t_true).mean())\n",
        "\n",
        "    duration_s = len(df_eval) * float(CLIP_S)\n",
        "    cavg = compute_cavg_macs(duration_s, 0, 0, len(df_eval), MAC_STAGE1_PER_CALL, 0.0, MACS_STAGE3_DYMN)\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": \"S3_single_clip\",\n",
        "        \"stage2_name\": \"\",\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc, \"Top1_Acc\": top1,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": 0.0, \"Stage2_calls\": 0.0, \"Stage3_calls\": float(len(df_eval)),\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_stage2_stage3_single_clips(df_eval: pd.DataFrame, stage2_name: str, stage2_type: str, cfg: EvalConfig,\n",
        "                                    bc_frontend=None, bc_model=None):\n",
        "    y_true, y_pred, y_score = [], [], []\n",
        "    s2_calls, s3_calls = 0, 0\n",
        "\n",
        "    for i in range(len(df_eval)):\n",
        "        fn = df_eval.loc[i, \"filename\"]\n",
        "        yt = int(df_eval.loc[i, \"is_emergency\"])\n",
        "        x = _to_wave_tensor_from_filename(fn)\n",
        "\n",
        "        if stage2_type == \"mn\":\n",
        "            pd = float(stage2_mn_pdanger(x).item())\n",
        "            mac_s2 = MACS_STAGE2_MN\n",
        "        else:\n",
        "            pd = float(bcresnet_predict_pdanger(bc_frontend, bc_model, x[:, 0, :]).item())\n",
        "            mac_s2 = MACS_STAGE2_BC\n",
        "        s2_calls += 1\n",
        "\n",
        "        escalate = (pd >= cfg.stage2_gate)\n",
        "        if cfg.stage2_uncert_lo is not None and cfg.stage2_uncert_hi is not None:\n",
        "            escalate = escalate or (cfg.stage2_uncert_lo <= pd <= cfg.stage2_uncert_hi)\n",
        "\n",
        "        if not escalate:\n",
        "            yp = 0\n",
        "        else:\n",
        "            t = int(stage3_predict_target(x).item())\n",
        "            cat = target_to_cat[t]\n",
        "            yp = 1 if cat in EMERGENCY_CATS else 0\n",
        "            s3_calls += 1\n",
        "\n",
        "        y_true.append(yt); y_pred.append(yp); y_score.append(pd)\n",
        "\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "\n",
        "    duration_s = len(df_eval) * float(CLIP_S)\n",
        "    cavg = compute_cavg_macs(duration_s, 0, s2_calls, s3_calls, MAC_STAGE1_PER_CALL, mac_s2, MACS_STAGE3_DYMN)\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": \"S2+S3_single_clip\",\n",
        "        \"stage2_name\": stage2_name,\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc, \"Top1_Acc\": np.nan,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": 0.0, \"Stage2_calls\": float(s2_calls), \"Stage3_calls\": float(s3_calls),\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 2) Soundscape evaluator (S3, S1+S3, S2+S3, S1+S2+S3)\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def eval_soundscape_pipeline(wave, ann, pipeline, cfg: EvalConfig,\n",
        "                             stage1_gate=None,\n",
        "                             stage2_type=None, stage2_name=None,\n",
        "                             bc_frontend=None, bc_model=None):\n",
        "    duration_s = len(wave) / SR\n",
        "    decision_times, y_true = build_gt_emergency_windows_soundscape(ann, duration_s, cfg.decision_hop_s, cfg.label_win_s)\n",
        "\n",
        "    stage1_hops = 0\n",
        "    stage1_events = 0\n",
        "    open_mask = None\n",
        "    if stage1_gate is not None:\n",
        "        trig_times, hop_s, stage1_hops, stage1_events = stage1_trigger_times(stage1_gate, wave)\n",
        "        open_mask = gate_open_mask(decision_times, trig_times, hold_s=cfg.label_win_s)\n",
        "\n",
        "    y_pred = np.zeros(len(decision_times), dtype=np.int64)\n",
        "    y_score = np.zeros(len(decision_times), dtype=np.float32)\n",
        "    n_s2 = 0\n",
        "    n_s3 = 0\n",
        "\n",
        "    em_targets = [cat_to_target[c] for c in EMERGENCY_CATS]\n",
        "\n",
        "    for i, t in enumerate(decision_times):\n",
        "        run_s2 = False\n",
        "        run_s3 = False\n",
        "\n",
        "        if pipeline == \"S3\":\n",
        "            run_s3 = True\n",
        "        elif pipeline == \"S1+S3\":\n",
        "            run_s3 = bool(open_mask[i])\n",
        "        elif pipeline == \"S2+S3\":\n",
        "            run_s2 = True\n",
        "        elif pipeline == \"S1+S2+S3\":\n",
        "            run_s2 = bool(open_mask[i])\n",
        "        else:\n",
        "            raise ValueError(pipeline)\n",
        "\n",
        "        seg = get_trailing_window(wave, float(t), cfg.label_win_s)\n",
        "        x = torch.from_numpy(seg)[None, None, :].to(DEVICE)\n",
        "\n",
        "        if run_s2:\n",
        "            n_s2 += 1\n",
        "            if stage2_type == \"mn\":\n",
        "                pd = float(stage2_mn_pdanger(x).item())\n",
        "                mac_s2_call = MACS_STAGE2_MN\n",
        "            else:\n",
        "                pd = float(bcresnet_predict_pdanger(bc_frontend, bc_model, x[:,0,:]).item())\n",
        "                mac_s2_call = MACS_STAGE2_BC\n",
        "            y_score[i] = pd\n",
        "\n",
        "            escalate = (pd >= cfg.stage2_gate)\n",
        "            if cfg.stage2_uncert_lo is not None and cfg.stage2_uncert_hi is not None:\n",
        "                escalate = escalate or (cfg.stage2_uncert_lo <= pd <= cfg.stage2_uncert_hi)\n",
        "\n",
        "            run_s3 = escalate\n",
        "        else:\n",
        "            mac_s2_call = 0.0\n",
        "\n",
        "        if run_s3:\n",
        "            n_s3 += 1\n",
        "            t_hat = int(stage3_predict_target(x).item())\n",
        "            cat = target_to_cat[t_hat]\n",
        "            y_pred[i] = 1 if cat in EMERGENCY_CATS else 0\n",
        "\n",
        "            # if no Stage2 score, use Stage3 emergency prob mass as score\n",
        "            if not run_s2:\n",
        "                xm = wave_to_mel_128(mel128, x)\n",
        "                logits = dymn_50(xm)[0]  # (1,50)\n",
        "                p = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
        "                y_score[i] = float(p[em_targets].sum())\n",
        "\n",
        "    prec, rec, f1, tp, fp, fn = _prec_rec_f1(y_true, y_pred)\n",
        "    auroc = _auroc_rank(y_true, y_score)\n",
        "    ttd = _ttd_seconds(ann, decision_times, y_pred)\n",
        "\n",
        "    # CLEAN + interpretable gate metrics:\n",
        "    #   TR_s1_per_min: Stage1 trigger events per minute (only for Stage1 pipelines)\n",
        "    #   S3_rate: fraction of decision steps where Stage3 ran (directly interpretable)\n",
        "    tr_per_min = float(stage1_events / max(1e-9, duration_s/60.0)) if stage1_gate is not None else float(\"nan\")\n",
        "    s3_rate = float(n_s3 / max(1, len(decision_times)))\n",
        "\n",
        "    # compute\n",
        "    if stage2_type == \"mn\":\n",
        "        mac_s2_per_call = MACS_STAGE2_MN\n",
        "    elif stage2_type == \"bc\":\n",
        "        mac_s2_per_call = MACS_STAGE2_BC\n",
        "    else:\n",
        "        mac_s2_per_call = 0.0\n",
        "\n",
        "    cavg = compute_cavg_macs(\n",
        "        duration_s=duration_s,\n",
        "        n_stage1_calls=(stage1_hops if stage1_gate is not None else 0),\n",
        "        n_stage2_calls=n_s2,\n",
        "        n_stage3_calls=n_s3,\n",
        "        mac_stage1_per_call=MAC_STAGE1_PER_CALL,\n",
        "        mac_stage2_per_call=mac_s2_per_call,\n",
        "        mac_stage3_per_call=MACS_STAGE3_DYMN,\n",
        "    )\n",
        "    eui = f1 / max(1e-12, cavg)\n",
        "\n",
        "    return {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"stage2_name\": stage2_name or \"\",\n",
        "        \"EF1\": f1, \"Prec\": prec, \"Rec\": rec, \"AUROC\": auroc,\n",
        "        \"TR\": tr_per_min,           # repurposed: Stage1 triggers per minute\n",
        "        \"DER\": s3_rate,             # repurposed: Stage3 duty rate on decision grid\n",
        "        \"TTD_sec\": ttd,\n",
        "        \"Cavg_MACs_per_s\": cavg, \"EUI\": eui,\n",
        "        \"Stage1_calls\": float(stage1_hops if stage1_gate is not None else 0),\n",
        "        \"Stage2_calls\": float(n_s2),\n",
        "        \"Stage3_calls\": float(n_s3),\n",
        "        \"Top1_Acc\": np.nan,\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# Prepare eval split (all 2000 clips)\n",
        "# ============================================================\n",
        "df_eval = df.copy().reset_index(drop=True)\n",
        "print(\"[BIG] df_eval:\", len(df_eval), \"| emergencies:\", int(df_eval[\"is_emergency\"].sum()))\n",
        "\n",
        "# ============================================================\n",
        "# Load all Stage2 variants (MN + all BC ckpts)\n",
        "# ============================================================\n",
        "BC_MODELS = {}\n",
        "for name, ckpt in BCRESNET_CKPTS.items():\n",
        "    tau, fe, m = load_bcresnet_binary(ckpt, device=DEVICE)\n",
        "    BC_MODELS[name] = {\"tau\": tau, \"frontend\": fe, \"model\": m}\n",
        "print(\"[BIG] Loaded BCResNet variants:\", list(BC_MODELS.keys()))\n",
        "\n",
        "STAGE2_LIST = [(\"mn04_binary\", \"mn\", None)]\n",
        "for name in BC_MODELS.keys():\n",
        "    STAGE2_LIST.append((name, \"bc\", BC_MODELS[name]))\n",
        "print(\"[BIG] Stage2 models:\", [x[0] for x in STAGE2_LIST])\n",
        "\n",
        "# ============================================================\n",
        "# Run experiments\n",
        "# ============================================================\n",
        "results = []\n",
        "\n",
        "# -------------------------\n",
        "# 1) Single clips\n",
        "# -------------------------\n",
        "r = eval_stage3_single_clips(df_eval, batch_size=BATCH_SIZE)\n",
        "r.update({\"Experiment\": \"Stage3_single_clips\", \"Scenario\": \"\", \"Stage1\": \"\"})\n",
        "results.append(r)\n",
        "print(\"[BIG] OK Stage3_single_clips | EF1:\", r[\"EF1\"], \"| Cavg:\", r[\"Cavg_MACs_per_s\"])\n",
        "\n",
        "for s2_name, s2_type, bc_pack in STAGE2_LIST:\n",
        "    if s2_type == \"mn\":\n",
        "        r = eval_stage2_stage3_single_clips(df_eval, s2_name, \"mn\", EVAL_CFG)\n",
        "    else:\n",
        "        r = eval_stage2_stage3_single_clips(df_eval, s2_name, \"bc\", EVAL_CFG,\n",
        "                                            bc_frontend=bc_pack[\"frontend\"], bc_model=bc_pack[\"model\"])\n",
        "    r.update({\"Experiment\": \"Stage2+Stage3_single_clips\", \"Scenario\": \"\", \"Stage1\": \"\"})\n",
        "    results.append(r)\n",
        "    print(\"[BIG] OK S2+S3 clips:\", s2_name, \"| EF1:\", r[\"EF1\"], \"| S3 calls:\", r[\"Stage3_calls\"], \"| Cavg:\", r[\"Cavg_MACs_per_s\"])\n",
        "\n",
        "# -------------------------\n",
        "# 2) Soundscapes\n",
        "# -------------------------\n",
        "for scen_idx, scen in enumerate(SCENARIOS):\n",
        "    seed = SOUNDSCAPE_SEED_BASE + scen_idx*97\n",
        "    wave, ann = build_soundscape(scen, seed=seed)\n",
        "\n",
        "    # 2a) S3 only\n",
        "    r = eval_soundscape_pipeline(wave, ann, pipeline=\"S3\", cfg=EVAL_CFG,\n",
        "                                 stage1_gate=None, stage2_type=None, stage2_name=None)\n",
        "    r.update({\"Experiment\": \"Stage3_soundscapes\", \"Scenario\": scen.name, \"Stage1\": \"\"})\n",
        "    results.append(r)\n",
        "    print(\"[BIG] OK S3 soundscape:\", scen.name, \"| EF1:\", r[\"EF1\"], \"| S3 rate:\", r[\"DER\"])\n",
        "\n",
        "    # 2b) S1 + S3 (all DSP gates)\n",
        "    for s1_name, gate in DSP_GATES.items():\n",
        "        r = eval_soundscape_pipeline(wave, ann, pipeline=\"S1+S3\", cfg=EVAL_CFG,\n",
        "                                     stage1_gate=gate, stage2_type=None, stage2_name=None)\n",
        "        r.update({\"Experiment\": \"Stage1+Stage3_soundscapes\", \"Scenario\": scen.name, \"Stage1\": s1_name})\n",
        "        results.append(r)\n",
        "\n",
        "    # 2c) S2 + S3 (all Stage2)\n",
        "    for s2_name, s2_type, bc_pack in STAGE2_LIST:\n",
        "        if s2_type == \"mn\":\n",
        "            r = eval_soundscape_pipeline(wave, ann, pipeline=\"S2+S3\", cfg=EVAL_CFG,\n",
        "                                         stage1_gate=None, stage2_type=\"mn\", stage2_name=s2_name)\n",
        "        else:\n",
        "            r = eval_soundscape_pipeline(wave, ann, pipeline=\"S2+S3\", cfg=EVAL_CFG,\n",
        "                                         stage1_gate=None, stage2_type=\"bc\", stage2_name=s2_name,\n",
        "                                         bc_frontend=bc_pack[\"frontend\"], bc_model=bc_pack[\"model\"])\n",
        "        r.update({\"Experiment\": \"Stage2+Stage3_soundscapes\", \"Scenario\": scen.name, \"Stage1\": \"\"})\n",
        "        results.append(r)\n",
        "\n",
        "    # 2d) S1 + S2 + S3 (DSP  Stage2)\n",
        "    for s1_name, gate in DSP_GATES.items():\n",
        "        for s2_name, s2_type, bc_pack in STAGE2_LIST:\n",
        "            if s2_type == \"mn\":\n",
        "                r = eval_soundscape_pipeline(wave, ann, pipeline=\"S1+S2+S3\", cfg=EVAL_CFG,\n",
        "                                             stage1_gate=gate, stage2_type=\"mn\", stage2_name=s2_name)\n",
        "            else:\n",
        "                r = eval_soundscape_pipeline(wave, ann, pipeline=\"S1+S2+S3\", cfg=EVAL_CFG,\n",
        "                                             stage1_gate=gate, stage2_type=\"bc\", stage2_name=s2_name,\n",
        "                                             bc_frontend=bc_pack[\"frontend\"], bc_model=bc_pack[\"model\"])\n",
        "            r.update({\"Experiment\": \"Stage1+Stage2+Stage3_soundscapes\", \"Scenario\": scen.name, \"Stage1\": s1_name})\n",
        "            results.append(r)\n",
        "\n",
        "print(\"[BIG] Done. Total rows:\", len(results))\n",
        "\n",
        "# ============================================================\n",
        "# Summarize (neat report columns only; no redundancy)\n",
        "# ============================================================\n",
        "res_df = pd.DataFrame(results)\n",
        "\n",
        "keep_cols = [\n",
        "    \"Experiment\", \"Scenario\", \"Stage1\", \"stage2_name\", \"pipeline\",\n",
        "    \"EF1\", \"Prec\", \"Rec\", \"AUROC\",\n",
        "    \"TR\", \"DER\", \"TTD_sec\",                    # TR=Stage1 triggers/min, DER=Stage3 duty rate\n",
        "    \"Cavg_MACs_per_s\", \"EUI\",\n",
        "    \"Stage1_calls\", \"Stage2_calls\", \"Stage3_calls\",\n",
        "    \"Top1_Acc\"\n",
        "]\n",
        "for c in keep_cols:\n",
        "    if c not in res_df.columns:\n",
        "        res_df[c] = np.nan\n",
        "res_df = res_df[keep_cols].copy()\n",
        "\n",
        "# Sort: best EUI first within each experiment\n",
        "res_df[\"EUI_sort\"] = res_df[\"EUI\"].fillna(-1.0)\n",
        "res_df = res_df.sort_values([\"Experiment\", \"Scenario\", \"EUI_sort\"], ascending=[True, True, False]).drop(columns=[\"EUI_sort\"])\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "save_path = os.path.join(OUT_DIR, \"results_summary.csv\")\n",
        "res_df.to_csv(save_path, index=False)\n",
        "print(\"[BIG] Saved:\", save_path)\n",
        "\n",
        "res_df.head(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "uw_Orprzl5mz",
        "outputId": "bd38166d-80a9-4557-893c-958d0ebe51a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Zipped: /content/echo_guard_runs_20260114_134030.zip\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f81fbcad-ced5-48e7-9c9d-e3fdc95d2c7a\", \"echo_guard_runs_20260114_134030.zip\", 7283)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Download triggered.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[OK] Copied OUT_DIR to Drive: /content/drive/MyDrive/echo_guard_runs_exports/echo_guard_runs_20260114_134030\n",
            "[OK] Copied ZIP to Drive: /content/drive/MyDrive/echo_guard_runs_exports/echo_guard_runs_20260114_134030.zip\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# ZIP + DOWNLOAD OUT_DIR + COPY TO GOOGLE DRIVE\n",
        "# =========================\n",
        "import os, subprocess\n",
        "from datetime import datetime\n",
        "\n",
        "assert \"OUT_DIR\" in globals(), \"OUT_DIR is not defined\"\n",
        "out_dir = OUT_DIR\n",
        "assert os.path.isdir(out_dir), f\"OUT_DIR not found: {out_dir}\"\n",
        "\n",
        "# 1) Make a zip in /content\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_path = f\"/content/{os.path.basename(out_dir.rstrip('/'))}_{ts}.zip\"\n",
        "\n",
        "# Use system zip (fast + reliable in Colab)\n",
        "subprocess.run([\"bash\", \"-lc\", f\"cd '{out_dir}' && zip -r '{zip_path}' . -q\"], check=True)\n",
        "print(\"[OK] Zipped:\", zip_path)\n",
        "\n",
        "# 2) Download to your local machine\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "    print(\"[OK] Download triggered.\")\n",
        "except Exception as e:\n",
        "    print(\"[WARN] files.download failed (not in Colab UI?). Error:\", e)\n",
        "\n",
        "# 3) Copy BOTH the folder and zip to Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "    drive_root = \"/content/drive/MyDrive/echo_guard_runs_exports\"\n",
        "    os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    dst_dir = os.path.join(drive_root, f\"{os.path.basename(out_dir.rstrip('/'))}_{ts}\")\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "    # Copy folder contents (rsync keeps structure + is fast)\n",
        "    subprocess.run([\"bash\", \"-lc\", f\"rsync -a '{out_dir.rstrip('/')}/' '{dst_dir}/'\"], check=True)\n",
        "\n",
        "    # Copy zip too (so you have both)\n",
        "    dst_zip = os.path.join(drive_root, os.path.basename(zip_path))\n",
        "    subprocess.run([\"bash\", \"-lc\", f\"cp '{zip_path}' '{dst_zip}'\"], check=True)\n",
        "\n",
        "    print(\"[OK] Copied OUT_DIR to Drive:\", dst_dir)\n",
        "    print(\"[OK] Copied ZIP to Drive:\", dst_zip)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"[WARN] Drive copy failed. Error:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
